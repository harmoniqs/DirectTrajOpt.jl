var documenterSearchIndex = {"docs":
[{"location":"generated/concepts/problem_formulation/#Problem-Formulation","page":"Problem Formulation","title":"Problem Formulation","text":"","category":"section"},{"location":"generated/concepts/problem_formulation/#Overview","page":"Problem Formulation","title":"Overview","text":"DirectTrajOpt.jl solves direct trajectory optimization problems using direct transcription, which converts continuous-time optimal control problems into finite-dimensional nonlinear programs (NLPs).","category":"section"},{"location":"generated/concepts/problem_formulation/#The-General-Form","page":"Problem Formulation","title":"The General Form","text":"A trajectory optimization problem has the form:\n\nbeginalign*\nundersetx_1N u_1Ntextminimize quad  J(x_1N u_1N) \ntextsubject to quad  f(x_k+1 x_k u_k Delta t t_k) = 0 quad k = 1 ldots N-1\n c_k(x_k u_k) geq 0 quad k = 1 ldots N \n x_1 = x_textinit quad x_N = x_textgoal \nendalign*\n\nLet's break down each component:","category":"section"},{"location":"generated/concepts/problem_formulation/#Decision-Variables","page":"Problem Formulation","title":"Decision Variables","text":"","category":"section"},{"location":"generated/concepts/problem_formulation/#States:-x,-x,-...,-xₙ","page":"Problem Formulation","title":"States: x₁, x₂, ..., xₙ","text":"The state represents the configuration of your system at each time step.\n\nFor a robot arm: joint angles and velocities\nFor a spacecraft: position and velocity\nFor a quantum system: state vector or unitary operator","category":"section"},{"location":"generated/concepts/problem_formulation/#Controls:-u,-u,-...,-uₙ","page":"Problem Formulation","title":"Controls: u₁, u₂, ..., uₙ","text":"The control (or input) represents what you can actuate.\n\nFor a robot: motor torques\nFor a spacecraft: thruster forces\nFor quantum systems: electromagnetic field amplitudes","category":"section"},{"location":"generated/concepts/problem_formulation/#Time-Steps:-Δt,-Δt,-...,-Δtₙ","page":"Problem Formulation","title":"Time Steps: Δt₁, Δt₂, ..., Δtₙ","text":"The time step can be:\n\nFixed: All Δt are equal and constant\nFree: Each Δt is a decision variable (for minimum time problems)","category":"section"},{"location":"generated/concepts/problem_formulation/#Cost-Function:-J(x,-u)","page":"Problem Formulation","title":"Cost Function: J(x, u)","text":"The objective or cost function defines what you want to minimize. Common objectives include:","category":"section"},{"location":"generated/concepts/problem_formulation/#Control-Effort","page":"Problem Formulation","title":"Control Effort","text":"Minimize energy by penalizing large controls:\n\nJ = sum_k=1^N u_k^2\n\nusing DirectTrajOpt\nusing NamedTrajectories\nusing LinearAlgebra\n\nExample:\n\nN = 10\ntraj = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n)\n\nobj_effort = QuadraticRegularizer(:u, traj, 1.0)","category":"section"},{"location":"generated/concepts/problem_formulation/#Minimum-Time","page":"Problem Formulation","title":"Minimum Time","text":"Minimize trajectory duration:\n\nJ = sum_k=1^N Delta t_k\n\nobj_time = MinimumTimeObjective(traj, 0.1)  # weight = 0.1","category":"section"},{"location":"generated/concepts/problem_formulation/#Terminal-Cost","page":"Problem Formulation","title":"Terminal Cost","text":"Penalize deviation from goal at final time:\n\nJ = x_N - x_textgoal^2\n\nx_goal = [1.0, 0.0]\nobj_terminal = TerminalObjective(x -> norm(x - x_goal)^2, :x, traj)","category":"section"},{"location":"generated/concepts/problem_formulation/#Combined-Objectives","page":"Problem Formulation","title":"Combined Objectives","text":"You can add multiple objectives together:\n\nobj_combined = obj_effort + 0.1 * obj_time + 10.0 * obj_terminal","category":"section"},{"location":"generated/concepts/problem_formulation/#Dynamics-Constraints:-f(xₖ,-xₖ,-uₖ,-Δt,-t)-0","page":"Problem Formulation","title":"Dynamics Constraints: f(xₖ₊₁, xₖ, uₖ, Δt, t) = 0","text":"The dynamics constraints ensure the trajectory obeys the system's equations of motion. These are encoded via integrators that discretize continuous dynamics.","category":"section"},{"location":"generated/concepts/problem_formulation/#Continuous-Dynamics","page":"Problem Formulation","title":"Continuous Dynamics","text":"A continuous-time system has the form:\n\ndotx(t) = g(x(t) u(t) t)","category":"section"},{"location":"generated/concepts/problem_formulation/#Discrete-Approximation","page":"Problem Formulation","title":"Discrete Approximation","text":"Direct transcription approximates this using numerical integration:\n\nx_k+1 approx Phi(x_k u_k Delta t)\n\nwhere Φ is an integration scheme (e.g., Euler, RK4, matrix exponential).","category":"section"},{"location":"generated/concepts/problem_formulation/#Example:-Bilinear-Dynamics","page":"Problem Formulation","title":"Example: Bilinear Dynamics","text":"For control-linear systems:\n\ndotx = (G_0 + sum_i u_i G_i) x\n\nThe integrator uses matrix exponential:\n\nx_k+1 = exp(Delta t cdot G(u_k)) x_k\n\nG_drift = [-0.1 1.0; -1.0 -0.1]\nG_drives = [[0.0 1.0; 1.0 0.0]]\nG = u -> G_drift + sum(u .* G_drives)\n\nintegrator = BilinearIntegrator(G, :x, :u, traj)","category":"section"},{"location":"generated/concepts/problem_formulation/#Path-Constraints:-c(x,-u)-0","page":"Problem Formulation","title":"Path Constraints: c(x, u) ≥ 0","text":"Path constraints restrict states and controls along the trajectory.","category":"section"},{"location":"generated/concepts/problem_formulation/#Bounds","page":"Problem Formulation","title":"Bounds","text":"Simple box constraints on variables:\n\nu_min leq u_k leq u_max\n\ntraj_bounded = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (u = (-1.0, 1.0),),  # -1 ≤ u ≤ 1\n)","category":"section"},{"location":"generated/concepts/problem_formulation/#Nonlinear-Constraints","page":"Problem Formulation","title":"Nonlinear Constraints","text":"More complex constraints (e.g., obstacle avoidance, no-go zones):\n\nConstraint: keep control magnitude bounded\n\nconstraint = NonlinearKnotPointConstraint(\n    u -> [1.0 - norm(u)],  # 1 - ||u|| ≥ 0  →  ||u|| ≤ 1\n    :u,\n    traj;\n    equality = false,\n)","category":"section"},{"location":"generated/concepts/problem_formulation/#Boundary-Conditions","page":"Problem Formulation","title":"Boundary Conditions","text":"","category":"section"},{"location":"generated/concepts/problem_formulation/#Initial-Condition:-x-x_init","page":"Problem Formulation","title":"Initial Condition: x₁ = x_init","text":"Fixes the starting state.","category":"section"},{"location":"generated/concepts/problem_formulation/#Final-Condition:-xₙ-x_goal","page":"Problem Formulation","title":"Final Condition: xₙ = x_goal","text":"Fixes the ending state (or penalizes deviation via terminal cost).\n\ntraj_bc = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = [0.0, 0.0],),  # Fixed initial state\n    final = (x = [1.0, 0.0],),     # Fixed final state\n)","category":"section"},{"location":"generated/concepts/problem_formulation/#Direct-Transcription","page":"Problem Formulation","title":"Direct Transcription","text":"","category":"section"},{"location":"generated/concepts/problem_formulation/#Why-Direct-Transcription?","page":"Problem Formulation","title":"Why Direct Transcription?","text":"Mature solvers: Leverage powerful NLP solvers (Ipopt, SNOPT)\nConstraint handling: Natural way to include path constraints\nWarm starting: Can initialize with good guesses\nLarge problems: Scales well to thousands of variables","category":"section"},{"location":"generated/concepts/problem_formulation/#The-NLP-Formulation","page":"Problem Formulation","title":"The NLP Formulation","text":"After discretization, we have a finite-dimensional problem:\n\nbeginalign*\ntextminimize quad  J(z) \ntextsubject to quad  h(z) = 0 \n g(z) geq 0\nendalign*\n\nwhere z = [x₁, u₁, x₂, u₂, ..., xₙ, uₙ, Δt₁, ..., Δtₙ] is the decision vector.","category":"section"},{"location":"generated/concepts/problem_formulation/#When-to-Use-DirectTrajOpt","page":"Problem Formulation","title":"When to Use DirectTrajOpt","text":"DirectTrajOpt.jl is ideal when:\n\n✓ You have smooth dynamics\n✓ You need to handle constraints\n✓ You want flexibility in cost functions\n✓ You can provide reasonable initial guesses\n\nIt may not be ideal when:\n\n✗ Dynamics are highly discontinuous\n✗ You need guaranteed global optimality\n✗ Real-time performance is critical (use MPC frameworks)","category":"section"},{"location":"generated/concepts/problem_formulation/#Summary","page":"Problem Formulation","title":"Summary","text":"Component Mathematical Form Implementation\nDecision Variables x, u, Δt NamedTrajectory\nObjective J(x, u) Objective (sum of terms)\nDynamics f(xₖ₊₁, xₖ, uₖ) = 0 AbstractIntegrator\nPath Constraints c(x, u) ≥ 0 AbstractConstraint\nBoundary Conditions x₁ = x_init, xₙ = x_goal initial, final in trajectory","category":"section"},{"location":"generated/concepts/problem_formulation/#Next-Steps","page":"Problem Formulation","title":"Next Steps","text":"Trajectories: Learn how to construct NamedTrajectory objects\nIntegrators: Understand how dynamics are discretized\nObjectives: Explore different cost functions\nConstraints: Add complex constraints to your problems\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"lib/#Library","page":"Library","title":"Library","text":"","category":"section"},{"location":"lib/#Common-Interface","page":"Library","title":"Common Interface","text":"","category":"section"},{"location":"lib/#Constraints","page":"Library","title":"Constraints","text":"","category":"section"},{"location":"lib/#Integrators","page":"Library","title":"Integrators","text":"","category":"section"},{"location":"lib/#Objectives","page":"Library","title":"Objectives","text":"","category":"section"},{"location":"lib/#Problems","page":"Library","title":"Problems","text":"","category":"section"},{"location":"lib/#Solvers","page":"Library","title":"Solvers","text":"","category":"section"},{"location":"lib/#Ipopt-Solver","page":"Library","title":"Ipopt Solver","text":"","category":"section"},{"location":"lib/#DirectTrajOpt.CommonInterface","page":"Library","title":"DirectTrajOpt.CommonInterface","text":"Common interface for components (integrators and constraints).\n\nThis module defines the generic interface functions that both integrators and constraints implement through multiple dispatch. This avoids naming conflicts when both modules are imported.\n\n\n\n\n\n","category":"module"},{"location":"lib/#DirectTrajOpt.CommonInterface.eval_hessian_of_lagrangian","page":"Library","title":"DirectTrajOpt.CommonInterface.eval_hessian_of_lagrangian","text":"eval_hessian_of_lagrangian(component, traj::NamedTrajectory, μ::AbstractVector)\n\nHigh-level method to evaluate and return the full Hessian of the Lagrangian for the component.\n\nFor integrators: Computes the Hessian using ForwardDiff across all timesteps. For constraints: Calls hessianoflagrangian to fill compact storage, then assembles the full sparse Hessian.\n\nArguments\n\ncomponent: An integrator or constraint\ntraj: The trajectory providing values and structure\nμ: Lagrange multipliers\n\nReturns\n\nA sparse matrix representing the full Hessian μ'∇²f\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.CommonInterface.eval_jacobian","page":"Library","title":"DirectTrajOpt.CommonInterface.eval_jacobian","text":"eval_jacobian(component, traj::NamedTrajectory)\n\nHigh-level method to evaluate and return the full Jacobian for the component.\n\nFor integrators: Computes the Jacobian using ForwardDiff across all timesteps. For constraints: Calls jacobian! to fill compact storage, then assembles the full sparse Jacobian.\n\nArguments\n\ncomponent: An integrator or constraint\ntraj: The trajectory providing values and structure\n\nReturns\n\nA sparse matrix representing the full Jacobian\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.CommonInterface.evaluate!","page":"Library","title":"DirectTrajOpt.CommonInterface.evaluate!","text":"evaluate!(values, component, traj::NamedTrajectory)\n\nEvaluate the component (constraint or dynamics) and store the result in-place in values.\n\nFor integrators: Computes dynamics violations δ = f(x{k+1}, xk, u_k, ...) for all timesteps. For constraints: Computes constraint violations g(x) for all applicable timesteps/variables.\n\nArguments\n\nvalues: Pre-allocated vector to store the evaluation results\ncomponent: An integrator or constraint\ntraj: The trajectory providing values and structure\n\nReturns\n\nNothing (modifies values in-place)\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.CommonInterface.hessian_of_lagrangian","page":"Library","title":"DirectTrajOpt.CommonInterface.hessian_of_lagrangian","text":"hessian_of_lagrangian(component, μ, args...)\n\nCompute the Hessian of the Lagrangian (weighted by multipliers μ) for the component.\n\nArguments\n\ncomponent: An integrator, constraint, or other component\nμ: Lagrange multipliers\nargs...: Component-specific arguments (e.g., knot points, trajectory values)\n\nReturns\n\nA sparse matrix representing μ'∇²f\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.CommonInterface.hessian_of_lagrangian!","page":"Library","title":"DirectTrajOpt.CommonInterface.hessian_of_lagrangian!","text":"hessian_of_lagrangian!(μ∂²f, component, μ, args...)\n\nCompute the Hessian of the Lagrangian in-place, storing the result in μ∂²f.\n\nArguments\n\nμ∂²f: Pre-allocated sparse matrix for the Hessian\ncomponent: An integrator, constraint, or other component\nμ: Lagrange multipliers\nargs...: Component-specific arguments (e.g., knot points, trajectory values)\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.CommonInterface.hessian_structure","page":"Library","title":"DirectTrajOpt.CommonInterface.hessian_structure","text":"hessian_structure(component, traj::NamedTrajectory)\n\nReturn the sparsity structure of the Hessian of the Lagrangian for the given component.\n\nArguments\n\ncomponent: An integrator, constraint, or other component\ntraj: The trajectory providing dimension information\n\nReturns\n\nA sparse matrix representing the Hessian structure\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.CommonInterface.jacobian!","page":"Library","title":"DirectTrajOpt.CommonInterface.jacobian!","text":"jacobian!(∂f, component, args...)\n\nCompute the Jacobian of the component in-place, storing the result in ∂f.\n\nArguments\n\n∂f: Pre-allocated sparse matrix for the Jacobian\ncomponent: An integrator, constraint, or other component  \nargs...: Component-specific arguments (e.g., knot points, trajectory values)\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.CommonInterface.jacobian_structure","page":"Library","title":"DirectTrajOpt.CommonInterface.jacobian_structure","text":"jacobian_structure(component, traj::NamedTrajectory)\n\nReturn the sparsity structure of the Jacobian for the given component. This should return a sparse matrix with the same structure as the Jacobian, where non-zero entries indicate where partial derivatives exist.\n\nArguments\n\ncomponent: An integrator, constraint, or other component\ntraj: The trajectory providing dimension information\n\nReturns\n\nA sparse matrix representing the Jacobian structure\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.Constraints.AbstractConstraint","page":"Library","title":"DirectTrajOpt.Constraints.AbstractConstraint","text":"AbstractConstraint\n\nAbstract supertype for all constraints in a trajectory optimization problem.\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.AbstractLinearConstraint","page":"Library","title":"DirectTrajOpt.Constraints.AbstractLinearConstraint","text":"AbstractLinearConstraint <: AbstractConstraint\n\nAbstract type for linear constraints (bounds, equality, symmetry, etc.). Linear constraints are applied directly to the optimizer via MathOptInterface rather than through the NLP evaluator.\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.AbstractNonlinearConstraint","page":"Library","title":"DirectTrajOpt.Constraints.AbstractNonlinearConstraint","text":"AbstractNonlinearConstraint <: AbstractConstraint\n\nAbstract type for nonlinear constraints evaluated at each solver iteration.\n\nSubtypes must implement the CommonInterface methods and have a dim::Int field giving the total constraint dimension, plus an equality::Bool field indicating whether the constraint is g(x) = 0 (equality) or g(x) ≤ 0 (inequality).\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.AllEqualConstraint","page":"Library","title":"DirectTrajOpt.Constraints.AllEqualConstraint","text":"struct AllEqualConstraint <: AbstractLinearConstraint\n\nConstraint that all components of a variable should be equal to each other. Commonly used for fixed timesteps.\n\nFields\n\nvar_name::Symbol: Variable name to constrain\ncomponent_index::Int: Which component of the variable (1 for scalar variables)\nlabel::String: Constraint label\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.BoundsConstraint","page":"Library","title":"DirectTrajOpt.Constraints.BoundsConstraint","text":"struct BoundsConstraint <: AbstractLinearConstraint\n\nRepresents a box constraint defined by variable names. Indices and concrete bounds are computed in constrain!.\n\nFields\n\nvar_names::Union{Symbol, Vector{Symbol}}: Variable name(s) to constrain\ntimes::Union{Nothing, Vector{Int}}: Time indices (nothing for global variables)\nbounds_values::Union{Float64, Vector{Float64}, Tuple{Vector{Float64}, Vector{Float64}}}: Bound specification\nis_global::Bool: Whether this is a global variable constraint\nsubcomponents::Union{Nothing, UnitRange{Int}}: Optional subcomponent selection\nlabel::String: Constraint label\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.BoundsConstraint-Tuple{Symbol, AbstractVector{Int64}, Union{Float64, Tuple{Vector{Float64}, Vector{Float64}}, Vector{Float64}}}","page":"Library","title":"DirectTrajOpt.Constraints.BoundsConstraint","text":"BoundsConstraint(\n    name::Symbol,\n    ts::Vector{Int},\n    bounds::Union{Float64, Vector{Float64}, Tuple{Vector{Float64}, Vector{Float64}}};\n    subcomponents=nothing,\n    label=\"bounds constraint on trajectory variable $name\"\n)\n\nConstructs box constraint for trajectory variable. Indices are computed when applied to a trajectory.\n\nArguments\n\nname: Variable name\nts: Time indices\nbounds: Can be:\nScalar: symmetric bounds [-bounds, bounds]\nVector: symmetric bounds [-bounds, bounds] element-wise\nTuple: (lowerbounds, upperbounds)\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.EqualityConstraint","page":"Library","title":"DirectTrajOpt.Constraints.EqualityConstraint","text":"struct EqualityConstraint <: AbstractLinearConstraint\n\nRepresents a linear equality constraint defined by variable names. Indices are computed when constraint is applied in constrain!.\n\nFields\n\nvar_names::Union{Symbol, Vector{Symbol}}: Variable name(s) to constrain\ntimes::Union{Nothing, Vector{Int}}: Time indices (nothing for global variables)\nvalues::Vector{Float64}: Constraint values\nis_global::Bool: Whether this is a global variable constraint\nlabel::String: Constraint label\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.EqualityConstraint-Tuple{Symbol, AbstractVector{Int64}, Union{Float64, Vector{Float64}}}","page":"Library","title":"DirectTrajOpt.Constraints.EqualityConstraint","text":"EqualityConstraint(\n    name::Symbol,\n    ts::Vector{Int},\n    val::Union{Float64, Vector{Float64}};\n    label=\"equality constraint on trajectory variable $name\"\n)\n\nConstructs equality constraint for trajectory variable. Indices are computed when applied to a trajectory.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.L1SlackConstraint","page":"Library","title":"DirectTrajOpt.Constraints.L1SlackConstraint","text":"struct L1SlackConstraint <: AbstractLinearConstraint\n\nLinear constraint tying a slack variable to the absolute value of another variable.\n\nFor each timestep k and component i, enforces:\n\nv_ki leq s_ki quad -v_ki leq s_ki\nquad Longleftrightarrow quad v_ki leq s_ki\n\nThe bound s ≥ 0 is expected to come from the trajectory's bounds on the slack component. When combined with a LinearRegularizer on the slack variable, this yields an exact L1 penalty on v.\n\nFields\n\nvar_name::Symbol: Variable to penalize (e.g. :du)\nslack_name::Symbol: Slack variable name (e.g. :s_du)\ntimes::Vector{Int}: Time indices where constraint is applied\nlabel::String: Constraint label\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.L1SlackConstraint-Tuple{Symbol, Symbol, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.Constraints.L1SlackConstraint","text":"L1SlackConstraint(\n    var_name::Symbol,\n    slack_name::Symbol,\n    traj::NamedTrajectory;\n    times::AbstractVector{Int}=1:traj.N,\n    label=\"L1 slack constraint: |var_name| ≤ slack_name\"\n)\n\nConstruct an L1 slack constraint tying |var_name| to slack_name.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.NonlinearGlobalConstraint","page":"Library","title":"DirectTrajOpt.Constraints.NonlinearGlobalConstraint","text":"NonlinearGlobalConstraint{F} <: AbstractNonlinearConstraint\n\nConstraint applied to global (trajectory-wide) parameters only.\n\nComputes Jacobians and Hessians on-the-fly using automatic differentiation. For pre-allocated optimization, see Piccolissimo.OptimizedNonlinearGlobalConstraint.\n\nFields\n\ng::F: Constraint function mapping global variables -> constraint values\nglobal_names::Vector{Symbol}: Names of global variables the constraint depends on\nequality::Bool: If true, g(globals) = 0; if false, g(globals) ≤ 0\ndim::Int: Dimension of constraint output\nglobal_dim::Int: Combined dimension of all constrained global variables\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.NonlinearGlobalKnotPointConstraint","page":"Library","title":"DirectTrajOpt.Constraints.NonlinearGlobalKnotPointConstraint","text":"NonlinearGlobalKnotPointConstraint{F} <: AbstractNonlinearConstraint\n\nConstraint applied at individual knot points that also depends on global parameters.\n\nComputes Jacobians and Hessians on-the-fly using automatic differentiation. For pre-allocated optimization, see Piccolissimo.OptimizedNonlinearGlobalKnotPointConstraint.\n\nFields\n\ng::F: Constraint function mapping (knotpointvars..., global_vars..., params) -> constraint values\nvar_names::Vector{Symbol}: Names of knot point variables the constraint depends on\nglobal_names::Vector{Symbol}: Names of global variables the constraint depends on\ntimes::Vector{Int}: Time indices where constraint is applied\nequality::Bool: If true, g(x, globals) = 0; if false, g(x, globals) ≤ 0\nparams::Vector: Parameters for each time index\ng_dim::Int: Dimension of constraint output at each time step\nvar_dim::Int: Combined dimension of knot point variables\nglobal_dim::Int: Combined dimension of global variables\ncombined_dim::Int: vardim + globaldim\ndim::Int: Total constraint dimension (g_dim * length(times))\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.NonlinearKnotPointConstraint","page":"Library","title":"DirectTrajOpt.Constraints.NonlinearKnotPointConstraint","text":"NonlinearKnotPointConstraint{F} <: AbstractNonlinearConstraint\n\nConstraint applied at individual knot points over a trajectory.\n\nComputes Jacobians and Hessians on-the-fly using automatic differentiation. For pre-allocated optimization, see Piccolissimo.OptimizedNonlinearKnotPointConstraint.\n\nFields\n\ng::F: Constraint function mapping (variables..., params) -> constraint values\nvar_names::Vector{Symbol}: Names of trajectory variables the constraint depends on\nequality::Bool: If true, g(x) = 0; if false, g(x) ≤ 0\ntimes::Vector{Int}: Time indices where constraint is applied\nparams::Vector: Parameters for each time index (e.g., time-varying targets)\ng_dim::Int: Dimension of constraint output at each time step\nvar_dim::Int: Combined dimension of all constrained variables\ndim::Int: Total constraint dimension (g_dim * length(times))\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.NonlinearKnotPointConstraint-Tuple{AbstractVector, NamedTrajectories.StructKnotPoint.KnotPoint, Int64}","page":"Library","title":"DirectTrajOpt.Constraints.NonlinearKnotPointConstraint","text":"(constraint::NonlinearKnotPointConstraint)(δ, zₖ::KnotPoint, k::Int)\n\nEvaluate the constraint at a single knot point.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.SymmetryConstraint","page":"Library","title":"DirectTrajOpt.Constraints.SymmetryConstraint","text":"struct SymmetryConstraint <: AbstractLinearConstraint\n\nConstraint enforcing symmetry in trajectory variables across time. Even symmetry: x[t] = x[N-t+1] Odd symmetry: x[t] = -x[N-t+1]\n\nFields\n\nvar_name::Symbol: Variable name to constrain\ncomponent_indices::Vector{Int}: Which components of the variable\neven::Bool: True for even symmetry (x[t] = x[N-t+1]), false for odd (-x[t] = x[N-t+1])\ninclude_timestep::Bool: Whether to also enforce even symmetry on timesteps\nlabel::String: Constraint label\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.TimeConsistencyConstraint","page":"Library","title":"DirectTrajOpt.Constraints.TimeConsistencyConstraint","text":"struct TimeConsistencyConstraint <: AbstractLinearConstraint\n\nConstraint that enforces consistency between time values and timesteps:     t{k+1} = tk + Δt_k  for k = 1, ..., T-1\n\nThis is used when both absolute times (:t) and timesteps (:Δt) are stored in the trajectory and need to remain consistent during optimization.\n\nFields\n\ntime_name::Symbol: Name of the time variable (default :t)\ntimestep_name::Symbol: Name of the timestep variable (default :Δt)\nlabel::String: Constraint label\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Constraints.TimeConsistencyConstraint-Tuple{}","page":"Library","title":"DirectTrajOpt.Constraints.TimeConsistencyConstraint","text":"TimeConsistencyConstraint(;\n    time_name::Symbol=:t,\n    timestep_name::Symbol=:Δt,\n    label=\"time consistency constraint (t_{k+1} = t_k + Δt_k)\"\n)\n\nConstruct a constraint enforcing t{k+1} = tk + Δt_k for all k.\n\nArguments\n\ntime_name: Name of the time variable in the trajectory (default :t)\ntimestep_name: Name of the timestep variable in the trajectory (default :Δt)\nlabel: Constraint label for logging/debugging\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.TotalConstraint","page":"Library","title":"DirectTrajOpt.Constraints.TotalConstraint","text":"struct TotalConstraint <: AbstractLinearConstraint\n\nConstraint that the sum of a variable's components equals a target value. Commonly used for trajectory duration constraints.\n\nFields\n\nvar_name::Symbol: Variable name to sum\ncomponent_index::Int: Which component of the variable (1 for scalar variables)\nvalue::Float64: Target sum value\nlabel::String: Constraint label\n\nNote\n\nWhen applied to the trajectory's timestep variable, only the first N-1 timesteps are summed (the last knot point has no duration after it). For other variables, all N values are summed.\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.CommonInterface.eval_hessian_of_lagrangian-Tuple{NonlinearGlobalConstraint, NamedTrajectories.StructNamedTrajectory.NamedTrajectory, AbstractVector}","page":"Library","title":"DirectTrajOpt.CommonInterface.eval_hessian_of_lagrangian","text":"eval_hessian_of_lagrangian(constraint::NonlinearGlobalConstraint, traj::NamedTrajectory, μ::AbstractVector)\n\nCompute and return the full Hessian of the Lagrangian using automatic differentiation.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.CommonInterface.eval_hessian_of_lagrangian-Tuple{NonlinearGlobalKnotPointConstraint, NamedTrajectories.StructNamedTrajectory.NamedTrajectory, AbstractVector}","page":"Library","title":"DirectTrajOpt.CommonInterface.eval_hessian_of_lagrangian","text":"eval_hessian_of_lagrangian(constraint::NonlinearGlobalKnotPointConstraint, traj::NamedTrajectory, μ::AbstractVector)\n\nCompute and return the full Hessian of the Lagrangian using automatic differentiation.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.CommonInterface.eval_hessian_of_lagrangian-Tuple{NonlinearKnotPointConstraint, NamedTrajectories.StructNamedTrajectory.NamedTrajectory, AbstractVector}","page":"Library","title":"DirectTrajOpt.CommonInterface.eval_hessian_of_lagrangian","text":"eval_hessian_of_lagrangian(constraint::NonlinearKnotPointConstraint, traj::NamedTrajectory, μ::AbstractVector)\n\nCompute and return the full Hessian of the Lagrangian using automatic differentiation.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.CommonInterface.eval_jacobian-Tuple{NonlinearGlobalConstraint, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.CommonInterface.eval_jacobian","text":"eval_jacobian(constraint::NonlinearGlobalConstraint, traj::NamedTrajectory)\n\nCompute and return the full Jacobian using automatic differentiation.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.CommonInterface.eval_jacobian-Tuple{NonlinearGlobalKnotPointConstraint, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.CommonInterface.eval_jacobian","text":"eval_jacobian(constraint::NonlinearGlobalKnotPointConstraint, traj::NamedTrajectory)\n\nCompute and return the full Jacobian using automatic differentiation.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.CommonInterface.eval_jacobian-Tuple{NonlinearKnotPointConstraint, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.CommonInterface.eval_jacobian","text":"eval_jacobian(constraint::NonlinearKnotPointConstraint, traj::NamedTrajectory)\n\nCompute and return the full Jacobian using automatic differentiation.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.CommonInterface.evaluate!-Tuple{AbstractVector, NonlinearGlobalConstraint, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.CommonInterface.evaluate!","text":"evaluate!(values::AbstractVector, constraint::NonlinearGlobalConstraint, traj::NamedTrajectory)\n\nEvaluate the global constraint, storing results in-place in values. This is part of the common interface with integrators.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.CommonInterface.evaluate!-Tuple{AbstractVector, NonlinearGlobalKnotPointConstraint, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.CommonInterface.evaluate!","text":"evaluate!(values::AbstractVector, constraint::NonlinearGlobalKnotPointConstraint, traj::NamedTrajectory)\n\nEvaluate the global knot point constraint, storing results in-place in values. This is part of the common interface with integrators.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.CommonInterface.evaluate!-Tuple{AbstractVector, NonlinearKnotPointConstraint, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.CommonInterface.evaluate!","text":"evaluate!(values::AbstractVector, constraint::NonlinearKnotPointConstraint, traj::NamedTrajectory)\n\nEvaluate the constraint at all specified time indices, storing results in-place in values. This is part of the common interface with integrators.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.DurationConstraint-Tuple{Float64}","page":"Library","title":"DirectTrajOpt.Constraints.DurationConstraint","text":"DurationConstraint(value::Float64; label=\"duration constraint of $value\")\n\nConstraint that the total trajectory duration equals a target value. The trajectory's timestep variable is inferred when applied.\n\nNote\n\nDuration is computed as the sum of the first N-1 timesteps, since the final knot point represents the end state and has no duration after it.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.GlobalBoundsConstraint-Tuple{Symbol, Union{Float64, Tuple{Vector{Float64}, Vector{Float64}}, Vector{Float64}}}","page":"Library","title":"DirectTrajOpt.Constraints.GlobalBoundsConstraint","text":"GlobalBoundsConstraint(\n    name::Symbol,\n    bounds::Union{Float64, Vector{Float64}, Tuple{Vector{Float64}, Vector{Float64}}};\n    label=\"bounds constraint on global variable $name\"\n)\n\nConstructs box constraint for global variable. Indices are computed when applied to a trajectory.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.GlobalEqualityConstraint-Tuple{Symbol, Union{Float64, Vector{Float64}}}","page":"Library","title":"DirectTrajOpt.Constraints.GlobalEqualityConstraint","text":"GlobalEqualityConstraint(\n    name::Symbol,\n    val::Union{Float64, Vector{Float64}};\n    label=\"equality constraint on global variable $name\"\n)::EqualityConstraint\n\nConstructs equality constraint for global variable. Indices are computed when applied to a trajectory.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.SymmetricControlConstraint-Tuple{Symbol, Vector{Int64}}","page":"Library","title":"DirectTrajOpt.Constraints.SymmetricControlConstraint","text":"SymmetricControlConstraint(\n    name::Symbol,\n    idx::Vector{Int};\n    even=true,\n    include_timestep=true,\n    label=\"symmetry constraint on $name\"\n)\n\nConstraint enforcing symmetry on control variables. Indices are computed when applied to a trajectory.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.TimeStepsAllEqualConstraint-Tuple{}","page":"Library","title":"DirectTrajOpt.Constraints.TimeStepsAllEqualConstraint","text":"TimeStepsAllEqualConstraint(;label=\"timesteps all equal constraint\")\n\nConstraint that all timesteps are equal (for fixed-timestep trajectories). The trajectory's timestep variable is inferred when applied.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Constraints.get_full_hessian","page":"Library","title":"DirectTrajOpt.Constraints.get_full_hessian","text":"get_full_hessian(constraint, traj::NamedTrajectory)\n\nAssemble the full sparse Hessian matrix from compact per-timestep blocks.\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.Constraints.get_full_jacobian","page":"Library","title":"DirectTrajOpt.Constraints.get_full_jacobian","text":"get_full_jacobian(constraint, traj::NamedTrajectory)\n\nAssemble the full sparse Jacobian matrix from compact per-timestep blocks.\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.Constraints.hessian_of_lagrangian!","page":"Library","title":"DirectTrajOpt.Constraints.hessian_of_lagrangian!","text":"hessian_of_lagrangian!(constraint, traj::NamedTrajectory, μ::AbstractVector)\n\nCompute the Hessian of the Lagrangian (μ'g) for the constraint in-place.\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.Constraints.test_constraint-Tuple{AbstractNonlinearConstraint, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.Constraints.test_constraint","text":"test_constraint(\n    constraint::AbstractNonlinearConstraint,\n    traj::NamedTrajectory;\n    show_jacobian_diff=false,\n    show_hessian_diff=false,\n    test_equality=true,\n    atol=1e-5,\n    rtol=1e-5\n)\n\nTest that constraint Jacobian and Hessian match finite difference approximations.\n\nArguments\n\nconstraint: Constraint to test\ntraj: Trajectory to evaluate constraint on\n\nKeyword Arguments\n\nshow_jacobian_diff=false: Print detailed Jacobian differences\nshow_hessian_diff=false: Print detailed Hessian differences\ntest_equality=true: Test element-wise equality (vs norm-based test)\natol=1e-5: Absolute tolerance\nrtol=1e-5: Relative tolerance\n\nReturns\n\nTuple of (∂g, ∂gfinitediff, μ∂²g, μ∂²gfinitediff) for inspection\n\nExample\n\ng(x) = [norm(x) - 1.0]\nconstraint = NonlinearKnotPointConstraint(g, :x, traj)\ntest_constraint(constraint, traj)\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Integrators.AbstractIntegrator","page":"Library","title":"DirectTrajOpt.Integrators.AbstractIntegrator","text":"AbstractIntegrator\n\nAbstract supertype for all dynamics integrators.\n\nSubtypes must implement the CommonInterface methods:\n\nevaluate!(δ, integrator, traj) — compute dynamics residuals\neval_jacobian(integrator, traj) — compute sparse Jacobian\neval_hessian_of_lagrangian(integrator, traj, μ) — compute sparse Hessian of Lagrangian\n\nand must have fields x_dim::Int and dim::Int.\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Integrators.BilinearIntegrator","page":"Library","title":"DirectTrajOpt.Integrators.BilinearIntegrator","text":"BilinearIntegrator <: AbstractBilinearIntegrator\n\nIntegrator for control-linear dynamics of the form ẋ = G(u)x.\n\nThis integrator uses matrix exponential methods to compute accurate state transitions for bilinear systems where the system matrix depends linearly on the control input.\n\nFields\n\nG::Function: Function mapping control u to system matrix G(u)\nx_name::Symbol: State variable name\nu_name::Symbol: Control variable name\nx_dim::Int: Dimension of state variable\nvar_dim::Int: Combined dimension of all variables this integrator depends on (2*xdim + udim + 1)\ndim::Int: Total constraint dimension (x_dim * (N-1))\n∂fs::Vector{SparseMatrixCSC{Float64, Int}}: Pre-allocated compact Jacobian storage (xdim × vardim per timestep)\nμ∂²fs::Vector{SparseMatrixCSC{Float64, Int}}: Pre-allocated compact Hessian storage (vardim × vardim per timestep)\n\nConstructors\n\nBilinearIntegrator(G::Function, x::Symbol, u::Symbol, traj::NamedTrajectory)\n\nArguments\n\nG: Function taking control u and returning state matrix (xdim × xdim)\nx: State variable name\nu: Control variable name\ntraj: Trajectory structure used to determine dimensions and pre-allocate storage\n\nDynamics\n\nComputes the constraint: x{k+1} - exp(Δt * G(uk)) * x_k = 0 Dependencies: xₖ, uₖ, Δtₖ, xₖ₊₁\n\nExample\n\n# Linear dynamics: ẋ = (A + Σᵢ uᵢ Bᵢ) x\nA = [-0.1 1.0; -1.0 -0.1]\nB = [0.0 0.0; 0.0 1.0]\nG = u -> A + u[1] * B\n\nintegrator = BilinearIntegrator(G, :x, :u, traj)\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Integrators.DerivativeIntegrator","page":"Library","title":"DirectTrajOpt.Integrators.DerivativeIntegrator","text":"DerivativeIntegrator <: AbstractIntegrator\n\nIntegrator for derivative constraints of the form xₖ₊₁ - xₖ - Δt * ẋₖ = 0.\n\nThis enforces smoothness by relating a variable to its derivative.\n\nFields\n\nf::Function: Constraint function f(xₖ₊₁, xₖ, ẋₖ, Δtₖ) = xₖ₊₁ - xₖ - Δtₖ * ẋₖ\nx_name::Symbol: Variable name\nẋ_name::Symbol: Derivative variable name\nx_dim::Int: Dimension of variable\nvar_dim::Int: Combined dimension (2*x_dim + 1 for xₖ, ẋₖ, Δtₖ, xₖ₊₁)\ndim::Int: Total constraint dimension (x_dim * (N-1))\n∂fs::Vector{SparseMatrixCSC{Float64, Int}}: Compact Jacobian storage\nμ∂²fs::Vector{SparseMatrixCSC{Float64, Int}}: Compact Hessian storage\n\nExample\n\n# Enforce velocity smoothness: vₖ₊₁ - vₖ - Δt * aₖ = 0\nintegrator = DerivativeIntegrator(:v, :a, traj)\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Integrators.TimeDependentBilinearIntegrator","page":"Library","title":"DirectTrajOpt.Integrators.TimeDependentBilinearIntegrator","text":"TimeDependentBilinearIntegrator{F} <: AbstractBilinearIntegrator\n\nIntegrator for time-dependent bilinear dynamics of the form:\n\ndotx = G(u(t) t)  x\n\nwhere G is a matrix-valued function of both the control u and time t. The control is interpolated between knot points using a spline of the specified order (0 = zero-order hold, 1 = linear interpolation). Integration over each time step is performed with an ODE solver (Tsit5) on the normalized interval [0, 1].\n\nFields\n\nf::Function: Compiled residual function (x_{k+1}, x_k, p_k, t_k, Δt_k) -> residual\nx_name::Symbol: Name of the state variable in the trajectory\nu_name::Symbol: Name of the control variable in the trajectory\nt_name::Symbol: Name of the time variable in the trajectory\nspline_order::Int: Control interpolation order (0 or 1)\nx_dim::Int: Dimension of the state vector\nu_dim::Int: Dimension of the control vector\ndim::Int: Total constraint dimension x_dim * (N - 1)\n\nConstructor\n\nTimeDependentBilinearIntegrator(\n    G::Function, x::Symbol, u::Symbol, t::Symbol,\n    traj::NamedTrajectory;\n    spline_order::Int=1, solve_kwargs=(;)\n)\n\nArguments\n\nG: Function (u, t) -> Matrix returning the generator at control value u and time t\nx: State variable name\nu: Control variable name\nt: Time variable name\ntraj: Trajectory providing dimensions and structure\n\nKeyword Arguments\n\nspline_order=1: Order of control interpolation (0 for piecewise constant, 1 for linear)\nsolve_kwargs=(;): Additional keyword arguments passed to OrdinaryDiffEq.solve\n\nExample\n\nG(u, t) = [-0.1 1.0; -1.0 -0.1] + u[1] * [0.0 cos(t); cos(t) 0.0]\nintegrator = TimeDependentBilinearIntegrator(G, :x, :u, :t, traj)\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Integrators.dense-Tuple{Any, Any, Any}","page":"Library","title":"DirectTrajOpt.Integrators.dense","text":"dense(vals, structure, shape)\n\nConvert sparse data to dense matrix.\n\nArguments\n\nvals: vector of values\nstructure: vector of tuples of indices\nshape: tuple of matrix dimensions\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Integrators.get_hessian_of_lagrangian_structure-Tuple{AbstractIntegrator, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.Integrators.get_hessian_of_lagrangian_structure","text":"get_hessian_of_lagrangian_structure(integrator::AbstractIntegrator, traj::NamedTrajectory)\n\nReturn the sparsity pattern of the integrator's Hessian of the Lagrangian as a sparse matrix with ones at every potentially nonzero entry.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Integrators.get_jacobian_structure-Tuple{AbstractIntegrator, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.Integrators.get_jacobian_structure","text":"get_jacobian_structure(integrator::AbstractIntegrator, traj::NamedTrajectory)\n\nReturn the sparsity pattern of the integrator's Jacobian as a sparse matrix with ones at every potentially nonzero entry. Used by the solver to pre-allocate structure.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Integrators.show_diffs-Tuple{AbstractMatrix, AbstractMatrix}","page":"Library","title":"DirectTrajOpt.Integrators.show_diffs","text":"show_diffs(A::Matrix, B::Matrix)\n\nShow differences between matrices.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Integrators.test_integrator-Tuple{AbstractIntegrator, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.Integrators.test_integrator","text":"test_integrator(\n    integrator::AbstractIntegrator,\n    traj::NamedTrajectory;\n    show_jacobian_diff=false,\n    show_hessian_diff=false,\n    test_equality=true,\n    gauss_newton=false,\n    atol=1e-5,\n    rtol=1e-5\n)\n\nValidate an integrator's analytic Jacobian and Hessian against finite difference approximations. Intended for use in @testitem blocks.\n\nReturns\n\nTuple of (∂f, ∂f_finite_diff, μ∂²f, μ∂²f_finite_diff) for manual inspection.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Objectives.AbstractObjective","page":"Library","title":"DirectTrajOpt.Objectives.AbstractObjective","text":"AbstractObjective\n\nAbstract type for all objective functions in trajectory optimization.\n\nConcrete objective types must implement:\n\nobjective_value(obj, traj): Evaluate the objective at trajectory\ngradient!(∇, obj, traj): Compute gradient in-place (gradient is always dense)\nhessian_structure(obj, traj): Return sparsity structure as sparse matrix\nget_full_hessian(obj, traj): Return the full Hessian matrix\n\nObjectives support addition and scalar multiplication through CompositeObjective.\n\nNote: Unlike constraints and integrators, objective gradients are always dense, so no gradient_structure method is needed. The gradient! method fills the entire ∇ vector.\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Objectives.CompositeObjective","page":"Library","title":"DirectTrajOpt.Objectives.CompositeObjective","text":"CompositeObjective <: AbstractObjective\n\nRepresents a weighted sum or composition of multiple objectives.\n\nFields\n\nobjectives::Vector{AbstractObjective}: Individual objectives to combine\nweights::Vector{Float64}: Weight for each objective\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Objectives.GlobalKnotPointObjective","page":"Library","title":"DirectTrajOpt.Objectives.GlobalKnotPointObjective","text":"GlobalKnotPointObjective <: AbstractObjective\n\nKnot point objective that includes both time-varying and global trajectory components.\n\nObjective function ℓ operates on extracted variable values:\n\nJ = sum_k in texttimes Q_k ell(x_k g p_k)\n\nwhere ℓ receives both knot point variables and global variables concatenated.\n\nFields\n\nℓ::Function: Objective function mapping (knotvars + globalvars, params) → scalar cost\nvar_names::Vector{Symbol}: Names of trajectory variables at knot points\nglobal_names::Vector{Symbol}: Names of global trajectory variables\ntimes::Vector{Int}: Time indices where objective is evaluated\nparams::Vector: Parameters for each time index\nQs::Vector{Float64}: Weights for each time index\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Objectives.GlobalObjective","page":"Library","title":"DirectTrajOpt.Objectives.GlobalObjective","text":"GlobalObjective <: AbstractObjective\n\nObjective that only involves global (non-time-varying) trajectory components.\n\nObjective function ℓ operates on extracted global variable values:\n\nJ = Q cdot ell(textglobal_vars)\n\nFields\n\nℓ::Function: Objective function mapping global variables → scalar cost\nglobal_names::Vector{Symbol}: Names of global trajectory variables\nQ::Float64: Weight for the objective\n\nConstructor\n\nGlobalObjective(\n    ℓ::Function,\n    global_names::Union{Symbol, AbstractVector{Symbol}},\n    traj::NamedTrajectory;\n    Q::Float64=1.0\n)\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Objectives.KnotPointObjective","page":"Library","title":"DirectTrajOpt.Objectives.KnotPointObjective","text":"KnotPointObjective <: AbstractObjective\n\nKnot point summed objective function for trajectory optimization.\n\nStores the objective function ℓ that operates on extracted variable values:\n\nJ = sum_k in texttimes Q_k ell(x_k p_k)\n\nwhere ℓ is evaluated on trajectory variables at each knot point.\n\nFields\n\nℓ::Function: Objective function mapping (variables..., params) -> scalar cost\nvar_names::Vector{Symbol}: Names of trajectory variables the objective depends on\ntimes::Vector{Int}: Time indices where objective is evaluated\nparams::Vector: Parameters for each time index\nQs::Vector{Float64}: Weights for each time index\n∂²Ls::Vector{SparseMatrixCSC{Float64, Int}}: Preallocated sparse Hessian storage (one per timestep)\n\nConstructor\n\nKnotPointObjective(\n    ℓ::Function,\n    names::Union{Symbol, AbstractVector{Symbol}},\n    traj::NamedTrajectory,\n    params::AbstractVector;\n    times::AbstractVector{Int}=1:traj.N,\n    Qs::AbstractVector{Float64}=ones(length(times))\n)\n\nFor single variable: ℓ(x, p) where x is the variable values at a knot point For multiple variables: ℓ(x, u, p) where each argument corresponds to a variable in names\n\nExamples\n\n# Single variable\nobj = KnotPointObjective((x, _) -> norm(x)^2, :x, traj, fill(nothing, traj.N))\n\n# Multiple variables - concatenated\nobj = KnotPointObjective((xu, _) -> xu[1]^2 + xu[2]^2, [:x, :u], traj, fill(nothing, traj.N))\n\n# With parameters and weights\nobj = KnotPointObjective(\n    (x, p) -> norm(x - p)^2, :x, traj, [x_targets...];\n    times=1:10, Qs=[1.0, 2.0, ...]\n)\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Objectives.LinearRegularizer","page":"Library","title":"DirectTrajOpt.Objectives.LinearRegularizer","text":"LinearRegularizer <: AbstractObjective\n\nLinear regularization objective for a trajectory component.\n\nComputes:\n\nJ = sum_k in texttimes sum_i R_i cdot v_ki cdot Delta t_k\n\nUsed for L1 penalty via slack variables: when applied to a non-negative slack variable s ≥ 0 satisfying |du| ≤ s, minimizing Σ R_i s_i Δt yields the exact L1 norm of du.\n\nGradients and Hessians are computed analytically. The Hessian has only cross-terms ∂²J/∂v∂Δt = R_i (no diagonal).\n\nFields\n\nname::Symbol: Name of the variable to regularize\nR::Vector{Float64}: Per-component weights\ntimes::Vector{Int}: Time indices where regularization is applied\n\nConstructor\n\nLinearRegularizer(\n    name::Symbol,\n    traj::NamedTrajectory,\n    R::Union{Real, AbstractVector{<:Real}};\n    times::AbstractVector{Int}=1:traj.N\n)\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Objectives.MinimumTimeObjective","page":"Library","title":"DirectTrajOpt.Objectives.MinimumTimeObjective","text":"MinimumTimeObjective <: AbstractObjective\n\nObjective that minimizes total trajectory duration.\n\nComputes:\n\nJ = D sum_k=1^N-1 Delta t_k\n\nFields\n\nD::Float64: Scaling factor for minimum time objective\n\nConstructor\n\nMinimumTimeObjective(traj::NamedTrajectory; D::Float64=1.0)\nMinimumTimeObjective(traj::NamedTrajectory, D::Real)\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Objectives.NullObjective","page":"Library","title":"DirectTrajOpt.Objectives.NullObjective","text":"NullObjective <: AbstractObjective\n\nA zero objective that contributes nothing to the cost. Useful as a placeholder or when only constraints matter.\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Objectives.QuadraticRegularizer","page":"Library","title":"DirectTrajOpt.Objectives.QuadraticRegularizer","text":"QuadraticRegularizer <: AbstractObjective\n\nQuadratic regularization objective for a trajectory component.\n\nComputes:\n\nJ = sum_k in texttimes frac12 (v_k - v_textbaseline)^T R (v_k - v_textbaseline) Delta t\n\nGradients and Hessians are computed analytically.\n\nFields\n\nname::Symbol: Name of the variable to regularize\nR::Vector{Float64}: Diagonal weight matrix\nbaseline::Matrix{Float64}: Baseline values (column per timestep)\ntimes::Vector{Int}: Time indices where regularization is applied\n\nConstructor\n\nQuadraticRegularizer(\n    name::Symbol,\n    traj::NamedTrajectory,\n    R::Union{Real, AbstractVector{<:Real}};\n    baseline::AbstractMatrix{<:Real}=zeros(traj.dims[name], traj.N),\n    times::AbstractVector{Int}=1:traj.N\n)\n\n\n\n\n\n","category":"type"},{"location":"lib/#Base.:*-Tuple{Real, AbstractObjective}","page":"Library","title":"Base.:*","text":"Scale an objective by a constant.\n\n\n\n\n\n","category":"method"},{"location":"lib/#Base.:+-Tuple{AbstractObjective, AbstractObjective}","page":"Library","title":"Base.:+","text":"Add two objectives together. Flattens nested CompositeObjectives.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Objectives.TerminalObjective-Tuple{Function, AbstractVector{Symbol}, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.Objectives.TerminalObjective","text":"TerminalObjective(ℓ, names::Vector{Symbol}, traj; Q=1.0)\n\nCreate a terminal objective that operates on multiple variables concatenated together.\n\nThis is useful for objectives that need to access multiple state variables at the final timestep, such as coherent fidelity objectives.\n\nArguments\n\nℓ::Function: Loss function taking concatenated values from all named variables\nnames::Vector{Symbol}: Names of variables to concatenate\ntraj::NamedTrajectory: The trajectory\n\nKeyword Arguments\n\nQ::Float64=1.0: Weight on the objective\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Objectives.TerminalObjective-Tuple{Function, Symbol, Union{Symbol, AbstractVector{Symbol}}, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.Objectives.TerminalObjective","text":"TerminalObjective(\n    ℓ::Function,\n    name::Symbol,\n    global_names::Union{Symbol, AbstractVector{Symbol}},\n    traj::NamedTrajectory;\n    Q::Float64=1.0\n)\n\nCreate a terminal (final time) objective that includes both knot point and global variables. This is a convenience wrapper around GlobalKnotPointObjective with times=[traj.N] and Qs=[Q].\n\nArguments\n\nℓ::Function: Objective function mapping concatenated [knotvars; globalvars] → scalar\nname::Symbol: Name of the knot point variable\nglobal_names: Name(s) of global variable(s)\ntraj::NamedTrajectory: The trajectory\n\nExample\n\n# Terminal objective with knot point state and global parameter\nTerminalObjective(\n    xg -> norm(xg[1:2] - xg[3:4])^2,  # Distance from state to goal\n    :x, :x_goal, traj; Q=100.0\n)\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Objectives.get_full_hessian","page":"Library","title":"DirectTrajOpt.Objectives.get_full_hessian","text":"get_full_hessian(obj::AbstractObjective, traj::NamedTrajectory)\n\nCompute and return the full Hessian matrix of the objective.\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.Objectives.gradient!","page":"Library","title":"DirectTrajOpt.Objectives.gradient!","text":"gradient!(∇::AbstractVector, obj::AbstractObjective, traj::NamedTrajectory)\n\nCompute the gradient of the objective in-place. The gradient is always dense.\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.Objectives.hessian_structure","page":"Library","title":"DirectTrajOpt.Objectives.hessian_structure","text":"hessian_structure(obj::AbstractObjective, traj::NamedTrajectory)\n\nReturn the sparsity structure of the Hessian as a sparse matrix with non-zero entries where the Hessian has non-zero values.\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.Objectives.objective_value","page":"Library","title":"DirectTrajOpt.Objectives.objective_value","text":"objective_value(obj::AbstractObjective, traj::NamedTrajectory)\n\nEvaluate the objective function at the given trajectory.\n\n\n\n\n\n","category":"function"},{"location":"lib/#DirectTrajOpt.Objectives.test_objective-Tuple{AbstractObjective, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.Objectives.test_objective","text":"test_objective(\n    obj::AbstractObjective,\n    traj::NamedTrajectory;\n    show_gradient_diff=false,\n    show_hessian_diff=false,\n    test_equality=true,\n    atol=1e-5,\n    rtol=1e-5\n)\n\nTest an objective's gradient and Hessian implementations against finite differences.\n\nSimilar to test_integrator, this validates that computed derivatives match finite differences.\n\nArguments\n\nobj::AbstractObjective: The objective to test\ntraj::NamedTrajectory: Trajectory defining the problem structure\n\nKeyword Arguments\n\nshow_gradient_diff: Print element-wise differences in gradient\nshow_hessian_diff: Print element-wise differences in Hessian\ntest_equality: Test element-wise equality (vs. norm-based)\natol: Absolute tolerance for comparisons\nrtol: Relative tolerance for comparisons\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Problems.DirectTrajOptProblem","page":"Library","title":"DirectTrajOpt.Problems.DirectTrajOptProblem","text":"mutable struct DirectTrajOptProblem\n\nA direct trajectory optimization problem containing all information needed for setup and solution.\n\nFields\n\ntrajectory::NamedTrajectory: The trajectory containing optimization variables and data\nobjective::AbstractObjective: The objective function to minimize\nintegrators::Vector{<:AbstractIntegrator}: The integrators defining system dynamics\nconstraints::Vector{<:AbstractConstraint}: Constraints on the trajectory\n\nConstructors\n\nDirectTrajOptProblem(\n    traj::NamedTrajectory,\n    obj::AbstractObjective,\n    integrators::Vector{<:AbstractIntegrator};\n    constraints::Vector{<:AbstractConstraint}=AbstractConstraint[]\n)\n\nCreate a problem from a trajectory, objective, and integrators. Trajectory constraints (initial, final, bounds) are automatically extracted and added to the constraint list. The dynamics object is created by the evaluator at solve time.\n\nExample\n\ntraj = NamedTrajectory((x = rand(2, 10), u = rand(1, 10)), timestep=:Δt)\nobj = QuadraticRegularizer(:u, traj, 1.0)\nintegrator = BilinearIntegrator(G, :x, :u)\nprob = DirectTrajOptProblem(traj, obj, integrator)\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.Problems.get_trajectory_constraints-Tuple{NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.Problems.get_trajectory_constraints","text":"get_trajectory_constraints(traj::NamedTrajectory)\n\nExtract and create constraints from a NamedTrajectory's initial, final, and bounds specifications.\n\nArguments\n\ntraj::NamedTrajectory: Trajectory with specified initial conditions, final conditions, and/or bounds\n\nReturns\n\nVector{AbstractConstraint}: Vector of constraints including:\nInitial value equality constraints (from traj.initial)\nFinal value equality constraints (from traj.final)\nBounds constraints (from traj.bounds)\n\nDetails\n\nThe function automatically handles time indices based on which constraints are specified:\n\nIf both initial and final constraints exist for a component, bounds apply to interior points (2:N-1)\nIf only initial exists, bounds apply from second point onward (2:N)\nIf only final exists, bounds apply up to second-to-last point (1:N-1)\nIf neither exist, bounds apply to all time points (1:N)\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Problems.show_problem_details-Tuple{IO, DirectTrajOptProblem}","page":"Library","title":"DirectTrajOpt.Problems.show_problem_details","text":"show_problem_details(io::IO, prob::DirectTrajOptProblem)\n\nPrint the trajectory, objective, dynamics, and constraints sections of a problem.\n\nThis is used by both DirectTrajOptProblem and QuantumControlProblem display methods.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.IpoptSolverExt.IpoptEvaluator","page":"Library","title":"DirectTrajOpt.IpoptSolverExt.IpoptEvaluator","text":"IpoptEvaluator <: MOI.AbstractNLPEvaluator\n\nMathOptInterface NLP evaluator that bridges a DirectTrajOptProblem to Ipopt.\n\nHandles objective, gradient, constraint, Jacobian, and Hessian evaluation with pre-computed sparsity structures and linear index maps for efficient sparse matrix filling. Supports multi-threaded evaluation of independent integrators and constraints.\n\nConstructor\n\nIpoptEvaluator(prob::DirectTrajOptProblem; eval_hessian=true, verbose=false)\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.IpoptSolverExt.IpoptOptions","page":"Library","title":"DirectTrajOpt.IpoptSolverExt.IpoptOptions","text":"IpoptOptions <: AbstractSolverOptions\n\nConfiguration options for the Ipopt nonlinear solver. All fields map directly to Ipopt options.\n\nCommonly used fields\n\ntol::Float64 = 1e-8: Overall NLP convergence tolerance\nmax_iter::Int = 1_000: Maximum number of solver iterations\nmax_cpu_time = 1_000_000.0: Maximum CPU time in seconds\nconstr_viol_tol::Float64 = 1e-6: Constraint violation tolerance\neval_hessian = true: Whether to provide exact Hessians (false uses L-BFGS)\nlinear_solver = \"mumps\": Linear solver backend (\"mumps\", \"pardiso\", \"ma27\", etc.)\nprint_level::Int = 5: Ipopt output verbosity (0 = silent, 12 = maximum)\n\nExample\n\nopts = IpoptOptions(max_iter=200, tol=1e-6, print_level=0)\nsolve!(prob; options=opts)\n\n\n\n\n\n","category":"type"},{"location":"lib/#DirectTrajOpt.IpoptSolverExt._fill_hessian_values!-Union{Tuple{T}, Tuple{AbstractVector{T}, IpoptEvaluator, NamedTrajectories.StructNamedTrajectory.NamedTrajectory, T, AbstractVector{T}}} where T","page":"Library","title":"DirectTrajOpt.IpoptSolverExt._fill_hessian_values!","text":"_fill_hessian_values!(H, evaluator, Z, σ, μ)\n\nFill Hessian of Lagrangian values directly into output vector without building intermediate sparse matrices. Uses linear index map and direct SparseArrays access to eliminate allocations.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.IpoptSolverExt._fill_jacobian_values!-Tuple{AbstractVector, IpoptEvaluator, NamedTrajectories.StructNamedTrajectory.NamedTrajectory}","page":"Library","title":"DirectTrajOpt.IpoptSolverExt._fill_jacobian_values!","text":"_fill_jacobian_values!(∂, evaluator, Z)\n\nFill Jacobian values directly into the output vector without building intermediate sparse matrices. Uses pre-computed linear index map and direct SparseArrays access to eliminate allocations.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.IpoptSolverExt._update_trajectory_cache!-Tuple{IpoptEvaluator, AbstractVector}","page":"Library","title":"DirectTrajOpt.IpoptSolverExt._update_trajectory_cache!","text":"_update_trajectory_cache!(evaluator, Z⃗)\n\nUpdate the cached trajectory in-place with new data from Z⃗. Avoids repeated allocation of NamedTrajectory wrappers.\n\n\n\n\n\n","category":"method"},{"location":"lib/#DirectTrajOpt.Solvers.solve!-Tuple{DirectTrajOptProblem}","page":"Library","title":"DirectTrajOpt.Solvers.solve!","text":"solve!(\n    prob::DirectTrajOptProblem;\n    options::IpoptOptions=IpoptOptions(),\n    max_iter::Int=options.max_iter,\n    verbose::Bool=true,\n    linear_solver::String=options.linear_solver,\n    print_level::Int=options.print_level,\n    callback=nothing\n)\n\nSolve a direct trajectory optimization problem using Ipopt.\n\nArguments\n\nprob::DirectTrajOptProblem: The trajectory optimization problem to solve.\noptions::IpoptOptions: Ipopt solver options. Default is IpoptOptions().\nmax_iter::Int: Maximum number of iterations for the optimization solver.\nverbose::Bool: If true, print solver progress information.\nlinear_solver::String: Linear solver to use (e.g., \"mumps\", \"pardiso\", \"ma27\", \"ma57\", \"ma77\", \"ma86\", \"ma97\").\nprint_level::Int: Ipopt print level (0-12). Higher values provide more detailed output.\ncallback::Function: Optional callback function to execute during optimization.\n\nReturns\n\nnothing: The problem's trajectory is updated in place with the optimized solution.\n\nExample\n\nprob = DirectTrajOptProblem(trajectory, objective, dynamics)\nsolve!(prob; max_iter=100, verbose=true)\n\n\n\n\n\n","category":"method"},{"location":"generated/concepts/trajectories/#Trajectories","page":"Trajectories","title":"Trajectories","text":"","category":"section"},{"location":"generated/concepts/trajectories/#What-is-a-NamedTrajectory?","page":"Trajectories","title":"What is a NamedTrajectory?","text":"A NamedTrajectory is the central data structure in DirectTrajOpt.jl. It stores:\n\nStates and controls over time\nTime step information (fixed or variable)\nBoundary conditions (initial, final, goal)\nBounds on variables\nMetadata about which variables are controls, timesteps, etc.\n\nusing DirectTrajOpt\nusing NamedTrajectories","category":"section"},{"location":"generated/concepts/trajectories/#Basic-Construction","page":"Trajectories","title":"Basic Construction","text":"","category":"section"},{"location":"generated/concepts/trajectories/#Minimal-Example","page":"Trajectories","title":"Minimal Example","text":"N = 10  # number of time steps\n\nSpecify component data as a NamedTuple:\n\ndata = (\n    x = randn(2, N),    # 2D state\n    u = randn(1, N),    # 1D control\n    Δt = fill(0.1, N),   # time step\n)\n\ntraj = NamedTrajectory(\n    data;\n    timestep = :Δt,   # which variable represents time\n    controls = :u,     # which variable(s) are controls\n)\n\nAccess components:\n\nprintln(\"State at time 1: \", traj.x[:, 1])\nprintln(\"Control at time 5: \", traj.u[:, 5])\nprintln(\"Total time: \", sum(traj.Δt))","category":"section"},{"location":"generated/concepts/trajectories/#Trajectory-Components","page":"Trajectories","title":"Trajectory Components","text":"","category":"section"},{"location":"generated/concepts/trajectories/#States","page":"Trajectories","title":"States","text":"Variables that represent the system configuration. Can be multiple state vectors:\n\ntraj_multi = NamedTrajectory(\n    (\n        position = randn(3, N),  # 3D position\n        velocity = randn(3, N),  # 3D velocity\n        u = randn(2, N),\n        Δt = fill(0.1, N),\n    );\n    timestep = :Δt,\n    controls = :u,\n)","category":"section"},{"location":"generated/concepts/trajectories/#Controls","page":"Trajectories","title":"Controls","text":"Variables that you can actuate. Can specify multiple control variables:\n\ntraj_multi_control = NamedTrajectory(\n    (x = randn(2, N), u1 = randn(1, N), u2 = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = (:u1, :u2),\n)","category":"section"},{"location":"generated/concepts/trajectories/#Time-Steps","page":"Trajectories","title":"Time Steps","text":"Fixed time: All time steps equal (constant Δt)\n\ntraj_fixed_time = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,  # symbol pointing to timestep component\n    controls = :u,\n)\n\nFree time: Each time step is a decision variable (with bounds)\n\ntraj_free_time = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = (:u, :Δt),  # Include Δt in controls for optimization\n    bounds = (Δt = (0.01, 0.5),),  # Set bounds on time steps\n)","category":"section"},{"location":"generated/concepts/trajectories/#Boundary-Conditions","page":"Trajectories","title":"Boundary Conditions","text":"","category":"section"},{"location":"generated/concepts/trajectories/#Initial-Conditions","page":"Trajectories","title":"Initial Conditions","text":"Fix the starting state:\n\ntraj_initial = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = [0.0, 0.0],),  # x₁ = [0, 0]\n)\n\nCan also fix initial controls:\n\ntraj_initial_u = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = [0.0, 0.0], u = [0.0]),  # x₁ = [0, 0], u₁ = 0\n)","category":"section"},{"location":"generated/concepts/trajectories/#Final-Conditions","page":"Trajectories","title":"Final Conditions","text":"Fix the ending state:\n\ntraj_final = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    final = (x = [1.0, 0.0],),  # xₖ = [1, 0]\n)","category":"section"},{"location":"generated/concepts/trajectories/#Goal-Conditions","page":"Trajectories","title":"Goal Conditions","text":"Similar to final, but typically used with terminal cost instead of hard constraint:\n\ntraj_goal = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    goal = (x = [1.0, 0.0],),  # target: xₖ → [1, 0]\n)","category":"section"},{"location":"generated/concepts/trajectories/#Complete-Example","page":"Trajectories","title":"Complete Example","text":"traj_complete = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = [0.0, 0.0], u = [0.0]),\n    final = (u = [0.0],),\n    goal = (x = [1.0, 0.0],),\n)","category":"section"},{"location":"generated/concepts/trajectories/#Bounds-on-Variables","page":"Trajectories","title":"Bounds on Variables","text":"Bounds constrain variables to lie within specified ranges.","category":"section"},{"location":"generated/concepts/trajectories/#Scalar-Bounds-(Symmetric)","page":"Trajectories","title":"Scalar Bounds (Symmetric)","text":"A single number creates symmetric bounds: -bound ≤ var ≤ bound\n\ntraj_scalar_bound = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (u = 1.0,),  # -1 ≤ u ≤ 1 for all components\n)\n\nApplies to all components of the variable:\n\nprintln(\"u bounds: \", traj_scalar_bound.bounds.u)\n\nOutput: ([-1.0], [1.0])","category":"section"},{"location":"generated/concepts/trajectories/#Tuple-Bounds-(Asymmetric)","page":"Trajectories","title":"Tuple Bounds (Asymmetric)","text":"A tuple (lower, upper) creates asymmetric bounds:\n\ntraj_tuple_bound = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (u = (-2.0, 1.0),),  # -2 ≤ u ≤ 1\n)\n\nprintln(\"u bounds: \", traj_tuple_bound.bounds.u)\n\nOutput: ([-2.0], [1.0])","category":"section"},{"location":"generated/concepts/trajectories/#Vector-Bounds-(Component-wise-Symmetric)","page":"Trajectories","title":"Vector Bounds (Component-wise Symmetric)","text":"A vector creates component-specific symmetric bounds:\n\ntraj_vector_bound = NamedTrajectory(\n    (x = randn(2, N), u = randn(2, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (u = [1.0, 2.0],),  # -1 ≤ u₁ ≤ 1, -2 ≤ u₂ ≤ 2\n)\n\nprintln(\"u bounds: \", traj_vector_bound.bounds.u)\n\nOutput: ([-1.0, -2.0], [1.0, 2.0])","category":"section"},{"location":"generated/concepts/trajectories/#Tuple-of-Vectors-(Component-wise-Asymmetric)","page":"Trajectories","title":"Tuple of Vectors (Component-wise Asymmetric)","text":"The most general form - specify lower and upper for each component:\n\ntraj_full_bound = NamedTrajectory(\n    (x = randn(2, N), u = randn(2, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (u = ([-2.0, -1.0], [1.0, 3.0]),),  # -2 ≤ u₁ ≤ 1, -1 ≤ u₂ ≤ 3\n)\n\nprintln(\"u bounds: \", traj_full_bound.bounds.u)\n\nOutput: ([-2.0, -1.0], [1.0, 3.0])","category":"section"},{"location":"generated/concepts/trajectories/#Multiple-Variable-Bounds","page":"Trajectories","title":"Multiple Variable Bounds","text":"traj_multi_bounds = NamedTrajectory(\n    (x = randn(2, N), u = randn(2, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (\n        x = 5.0,           # -5 ≤ x ≤ 5 (both components)\n        u = [1.0, 2.0],    # component-specific\n        Δt = (0.05, 0.15),  # 0.05 ≤ Δt ≤ 0.15\n    ),\n)","category":"section"},{"location":"generated/concepts/trajectories/#Time-Step-Bounds","page":"Trajectories","title":"Time Step Bounds","text":"For free-time problems, bound the time steps:\n\ntraj_time_bounds = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (\n        u = 1.0,\n        Δt = (0.01, 0.2),  # 0.01 ≤ Δt ≤ 0.2\n    ),\n)","category":"section"},{"location":"generated/concepts/trajectories/#Accessing-Trajectory-Data","page":"Trajectories","title":"Accessing Trajectory Data","text":"","category":"section"},{"location":"generated/concepts/trajectories/#Direct-Access","page":"Trajectories","title":"Direct Access","text":"x_data = traj.x           # Get all states (2 × N matrix)\nu_data = traj.u           # Get all controls (1 × N matrix)\nx_final = traj.x[:, end]  # Get final state","category":"section"},{"location":"generated/concepts/trajectories/#Metadata","page":"Trajectories","title":"Metadata","text":"println(\"Number of time steps: \", traj.N)\nprintln(\"State dimension: \", traj.dims.x)\nprintln(\"Control dimension: \", traj.dims.u)\nprintln(\"Total dimension: \", traj.dim)","category":"section"},{"location":"generated/concepts/trajectories/#Time-Information","page":"Trajectories","title":"Time Information","text":"times = get_times(traj)  # Cumulative time at each knot point\ntotal_time = sum(traj.Δt)","category":"section"},{"location":"generated/concepts/trajectories/#Building-Trajectories-for-Optimization","page":"Trajectories","title":"Building Trajectories for Optimization","text":"","category":"section"},{"location":"generated/concepts/trajectories/#Good-Initialization-Matters","page":"Trajectories","title":"Good Initialization Matters","text":"Start with a reasonable guess:\n\nLinear interpolation between initial and final states\nZero or small random controls\nUniform time steps\n\nx_init = [0.0, 0.0]\nx_goal = [1.0, 1.0]\n\nLinear interpolation\n\nx_guess = hcat([x_init + (x_goal - x_init) * (t / (N-1)) for t = 0:(N-1)]...)\n\ntraj_good_init = NamedTrajectory(\n    (x = x_guess, u = zeros(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = x_init,),\n    final = (x = x_goal,),\n)","category":"section"},{"location":"generated/concepts/trajectories/#Common-Patterns","page":"Trajectories","title":"Common Patterns","text":"","category":"section"},{"location":"generated/concepts/trajectories/#State-Transfer-Problem","page":"Trajectories","title":"State Transfer Problem","text":"Drive from initial to final state with bounded controls\n\ntraj_transfer = NamedTrajectory(\n    (x = randn(3, 50), u = randn(2, 50), Δt = fill(0.1, 50));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = zeros(3),),\n    final = (x = ones(3),),\n    bounds = (u = 1.0,),\n)","category":"section"},{"location":"generated/concepts/trajectories/#Minimum-Time-Problem","page":"Trajectories","title":"Minimum Time Problem","text":"Free time steps, bounded, with time regularization\n\ntraj_mintime = NamedTrajectory(\n    (x = randn(2, 30), u = randn(1, 30), Δt = fill(0.1, 30));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = [0.0, 0.0],),\n    final = (x = [1.0, 0.0],),\n    bounds = (u = 1.0, Δt = (0.01, 0.5)),\n)","category":"section"},{"location":"generated/concepts/trajectories/#Smooth-Control-Problem","page":"Trajectories","title":"Smooth Control Problem","text":"Include control derivatives for smoothness\n\ntraj_smooth = NamedTrajectory(\n    (\n        x = randn(2, 40),\n        u = randn(2, 40),\n        du = zeros(2, 40),   # control derivative\n        Δt = fill(0.1, 40),\n    );\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = [0.0, 0.0], u = [0.0, 0.0]),\n    final = (x = [1.0, 0.0], u = [0.0, 0.0]),\n    bounds = (u = 1.0,),\n)","category":"section"},{"location":"generated/concepts/trajectories/#Summary","page":"Trajectories","title":"Summary","text":"Concept Syntax Example\nFixed time timestep=0.1 timestep=0.1\nFree time timestep=:Δt timestep=:Δt\nInitial condition initial=(x = [...],) initial=(x = [0, 0],)\nFinal condition final=(x = [...],) final=(x = [1, 0],)\nScalar bound bounds=(u = 1.0,) -1 ≤ u ≤ 1\nTuple bound bounds=(u = (-2, 1),) -2 ≤ u ≤ 1\nVector bound bounds=(u = [1, 2],) -1 ≤ u₁ ≤ 1, -2 ≤ u₂ ≤ 2\nFull bound bounds=(u = ([-2,-1], [1,3]),) -2 ≤ u₁ ≤ 1, -1 ≤ u₂ ≤ 3","category":"section"},{"location":"generated/concepts/trajectories/#Next-Steps","page":"Trajectories","title":"Next Steps","text":"Integrators: Learn how dynamics are encoded\nObjectives: Define cost functions on trajectories\nTutorials: See complete examples using trajectories\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/concepts/integrators/#Integrators","page":"Integrators","title":"Integrators","text":"","category":"section"},{"location":"generated/concepts/integrators/#What-are-Integrators?","page":"Integrators","title":"What are Integrators?","text":"Integrators discretize continuous-time dynamics into constraints for the NLP solver. They implement the relationship:\n\nx_k+1 = Phi(x_k u_k Delta t_k)\n\nwhere Φ approximates the continuous evolution ẋ = f(x, u, t).\n\nusing DirectTrajOpt\nusing NamedTrajectories\nusing LinearAlgebra","category":"section"},{"location":"generated/concepts/integrators/#BilinearIntegrator","page":"Integrators","title":"BilinearIntegrator","text":"","category":"section"},{"location":"generated/concepts/integrators/#Overview","page":"Integrators","title":"Overview","text":"Used for control-linear (bilinear) dynamics:\n\ndotx = (G_0 + sum_i u_i G_i) x\n\nwhere:\n\nG₀ is the drift term (dynamics with no control)\nGᵢ are the drive terms (how controls affect the system)\nuᵢ are the control inputs","category":"section"},{"location":"generated/concepts/integrators/#How-it-Works","page":"Integrators","title":"How it Works","text":"Uses the matrix exponential for exact integration:\n\nx_k+1 = exp(Delta t cdot G(u_k)) x_k\n\nwhere G(u) = G₀ + Σᵢ uᵢ Gᵢ.","category":"section"},{"location":"generated/concepts/integrators/#Example:-Simple-2D-System","page":"Integrators","title":"Example: Simple 2D System","text":"N = 50\ntraj = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = [1.0, 0.0],),\n    final = (x = [0.0, 1.0],),\n)\n\nDefine drift (natural dynamics) and drives (control terms)\n\nG_drift = [-0.1 1.0; -1.0 -0.1]     # Damped oscillator\nG_drives = [[0.0 1.0; 1.0 0.0]]     # Symmetric control coupling\n\nCreate generator function\n\nG = u -> G_drift + sum(u .* G_drives)\n\nCreate integrator\n\nintegrator = BilinearIntegrator(G, :x, :u, traj)","category":"section"},{"location":"generated/concepts/integrators/#Multiple-Drives-Example","page":"Integrators","title":"Multiple Drives Example","text":"traj_multi = NamedTrajectory(\n    (x = randn(3, N), u = randn(2, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n)\n\nG_drift_3d = [\n    0.0 1.0 0.0;\n    -1.0 0.0 0.0;\n    0.0 0.0 -0.1\n]\n\nG_drives_3d = [\n    [1.0 0.0 0.0; 0.0 0.0 0.0; 0.0 0.0 0.0],  # Drive 1\n    [0.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 0.0],   # Drive 2\n]\n\nG_multi = u -> G_drift_3d + sum(u .* G_drives_3d)\n\nintegrator_multi = BilinearIntegrator(G_multi, :x, :u, traj_multi)","category":"section"},{"location":"generated/concepts/integrators/#When-to-Use-BilinearIntegrator","page":"Integrators","title":"When to Use BilinearIntegrator","text":"✓ Quantum systems (Hamiltonian evolution) ✓ Rotating systems (attitude dynamics) ✓ Systems linear in controls ✓ When you want exact integration (no discretization error)","category":"section"},{"location":"generated/concepts/integrators/#TimeDependentBilinearIntegrator","page":"Integrators","title":"TimeDependentBilinearIntegrator","text":"","category":"section"},{"location":"generated/concepts/integrators/#Overview-2","page":"Integrators","title":"Overview","text":"For time-varying bilinear dynamics:\n\ndotx = (G_0(t) + sum_i u_i(t) G_i(t)) x\n\nThe generator function now depends on both control and time.","category":"section"},{"location":"generated/concepts/integrators/#Example:-Periodic-Disturbance","page":"Integrators","title":"Example: Periodic Disturbance","text":"traj_td = NamedTrajectory(\n    (\n        x = randn(2, N),\n        u = randn(1, N),\n        t = collect(range(0, 5, N)),  # time variable\n        Δt = fill(0.1, N),\n    );\n    timestep = :Δt,\n    controls = :u,\n)\n\nTime-dependent generator\n\nG_td = (u, t) -> [-0.1 + 0.5*sin(t) 1.0; -1.0 -0.1] + u[1] * [0.0 1.0; 1.0 0.0]\n\nintegrator_td = TimeDependentBilinearIntegrator(G_td, :x, :u, :t, traj_td)","category":"section"},{"location":"generated/concepts/integrators/#When-to-Use-TimeDependentBilinearIntegrator","page":"Integrators","title":"When to Use TimeDependentBilinearIntegrator","text":"✓ Time-varying Hamiltonians ✓ Systems with periodic forcing ✓ Carrier wave modulation (e.g., rotating frame transformations)","category":"section"},{"location":"generated/concepts/integrators/#DerivativeIntegrator","page":"Integrators","title":"DerivativeIntegrator","text":"","category":"section"},{"location":"generated/concepts/integrators/#Overview-3","page":"Integrators","title":"Overview","text":"Enforces derivative relationships between trajectory components:\n\nfracd(textvar)dt = textderiv\n\nThis is used for smoothness or when controls are derivatives of other variables.","category":"section"},{"location":"generated/concepts/integrators/#Example:-Smooth-Controls","page":"Integrators","title":"Example: Smooth Controls","text":"traj_smooth = NamedTrajectory(\n    (\n        x = randn(2, N),\n        u = randn(2, N),\n        du = zeros(2, N),   # control derivative\n        Δt = fill(0.1, N),\n    );\n    timestep = :Δt,\n    controls = :u,\n    initial = (u = [0.0, 0.0],),\n    final = (u = [0.0, 0.0],),\n)\n\nEnforce du/dt = du\n\nderiv_integrator = DerivativeIntegrator(:u, :du, traj_smooth)\n\nNow you can penalize du to get smooth controls: obj = QuadraticRegularizer(:u, trajsmooth, 1e-2) obj += QuadraticRegularizer(:du, trajsmooth, 1e-1)  # Smoothness penalty","category":"section"},{"location":"generated/concepts/integrators/#Multiple-Derivative-Orders","page":"Integrators","title":"Multiple Derivative Orders","text":"traj_smooth2 = NamedTrajectory(\n    (\n        x = randn(2, N),\n        u = randn(1, N),\n        du = zeros(1, N),\n        ddu = zeros(1, N),\n        Δt = fill(0.1, N),\n    );\n    timestep = :Δt,\n    controls = :u,\n)\n\nChain derivatives: d(u)/dt = du, d(du)/dt = ddu\n\nderiv_u = DerivativeIntegrator(:u, :du, traj_smooth2)\nderiv_du = DerivativeIntegrator(:du, :ddu, traj_smooth2)","category":"section"},{"location":"generated/concepts/integrators/#When-to-Use-DerivativeIntegrator","page":"Integrators","title":"When to Use DerivativeIntegrator","text":"✓ Enforce smooth, implementable controls ✓ Acceleration limits (when control is jerk) ✓ Tracking derivative information","category":"section"},{"location":"generated/concepts/integrators/#Combining-Multiple-Integrators","page":"Integrators","title":"Combining Multiple Integrators","text":"You can use multiple integrators simultaneously:\n\ntraj_combined = NamedTrajectory(\n    (x = randn(2, N), u = randn(2, N), du = zeros(2, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = [0.0, 0.0], u = [0.0, 0.0]),\n    final = (u = [0.0, 0.0],),\n)\n\nCreate problem with multiple integrators\n\nG_drift_simple = [-0.1 1.0; -1.0 -0.1]\nG_drives_simple = [[0.0 1.0; 1.0 0.0], [1.0 0.0; 0.0 1.0]]\nG_simple = u -> G_drift_simple + sum(u .* G_drives_simple)\n\nobj = QuadraticRegularizer(:u, traj_combined, 1e-2)\nobj += QuadraticRegularizer(:du, traj_combined, 1e-1)\n\nintegrators_combined = [\n    BilinearIntegrator(G_simple, :x, :u, traj_combined),\n    DerivativeIntegrator(:u, :du, traj_combined),\n]\n\nprob = DirectTrajOptProblem(traj_combined, obj, integrators_combined)","category":"section"},{"location":"generated/concepts/integrators/#Integration-Methods-Comparison","page":"Integrators","title":"Integration Methods Comparison","text":"Integrator Dynamics Type Accuracy Use Case\nBilinearIntegrator Control-linear Exact Quantum, rotation\nTimeDependentBilinearIntegrator Time-varying control-linear Exact Modulated systems\nDerivativeIntegrator Derivative relation Exact Smoothness","category":"section"},{"location":"generated/concepts/integrators/#Custom-Integrators","page":"Integrators","title":"Custom Integrators","text":"You can implement custom integrators by subtyping AbstractIntegrator and defining the constraint function. See the Advanced Topics section for details.","category":"section"},{"location":"generated/concepts/integrators/#Interface-Requirements","page":"Integrators","title":"Interface Requirements","text":"struct MyIntegrator <: AbstractIntegrator\n    # ... fields ...\nend\n\n# Implement constraint evaluation\nfunction (int::MyIntegrator)(δ, zₖ, zₖ₊₁, k)\n    # Compute constraint: δ = xₖ₊₁ - Φ(xₖ, uₖ, Δtₖ)\n    # where Φ is your integration scheme\nend","category":"section"},{"location":"generated/concepts/integrators/#Best-Practices","page":"Integrators","title":"Best Practices","text":"","category":"section"},{"location":"generated/concepts/integrators/#Initialization","page":"Integrators","title":"Initialization","text":"Start with good initial guesses for states and controls\nFor smooth control problems, initialize derivatives to zero\nUse linear interpolation for states between boundary conditions","category":"section"},{"location":"generated/concepts/integrators/#Performance","page":"Integrators","title":"Performance","text":"Matrix exponential (BilinearIntegrator) is efficient for small systems (n < 20)\nFor large systems, consider sparse representations\nDerivativeIntegrator is cheap (just finite differences)","category":"section"},{"location":"generated/concepts/integrators/#Numerical-Stability","page":"Integrators","title":"Numerical Stability","text":"Keep time steps reasonable (not too large)\nFor stiff systems, smaller time steps help\nBilinearIntegrator handles stiff systems well","category":"section"},{"location":"generated/concepts/integrators/#Common-Patterns","page":"Integrators","title":"Common Patterns","text":"","category":"section"},{"location":"generated/concepts/integrators/#Pattern-1:-Basic-Bilinear-Problem","page":"Integrators","title":"Pattern 1: Basic Bilinear Problem","text":"G_basic = u -> [-0.1 1.0; -1.0 -0.1] + u[1] * [0.0 1.0; 1.0 0.0]\n\nintegrator = BilinearIntegrator(G_basic, :x, :u, traj)","category":"section"},{"location":"generated/concepts/integrators/#Pattern-2:-Smooth-Control-Problem","page":"Integrators","title":"Pattern 2: Smooth Control Problem","text":"integrators = [     BilinearIntegrator(G, :x, :u, traj),     DerivativeIntegrator(:u, :du, traj) ]","category":"section"},{"location":"generated/concepts/integrators/#Pattern-3:-Time-Dependent-with-Smoothness","page":"Integrators","title":"Pattern 3: Time-Dependent with Smoothness","text":"integrators = [     TimeDependentBilinearIntegrator(G_td, :x, :u, :t, traj),     DerivativeIntegrator(:u, :du, traj) ]","category":"section"},{"location":"generated/concepts/integrators/#Summary","page":"Integrators","title":"Summary","text":"Key Takeaways:\n\nIntegrators convert continuous dynamics to discrete constraints\nBilinearIntegrator is the workhorse for control-linear systems\nDerivativeIntegrator adds smoothness\nYou can combine multiple integrators\nGood initialization helps convergence","category":"section"},{"location":"generated/concepts/integrators/#Next-Steps","page":"Integrators","title":"Next Steps","text":"Objectives: Learn how to define cost functions\nConstraints: Add bounds and path constraints\nTutorials: See integrators in complete examples\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/example/#Complete-Example:-Time-Optimal-Bilinear-Control","page":"Complete Example","title":"Complete Example: Time-Optimal Bilinear Control","text":"This example demonstrates solving a time-optimal trajectory optimization problem with:\n\nMultiple control inputs with bounds\nFree time steps (variable Δt)\nCombined objective (control effort + minimum time)\n\nusing DirectTrajOpt\nusing NamedTrajectories\nusing LinearAlgebra\nusing CairoMakie","category":"section"},{"location":"generated/example/#Problem-Setup","page":"Complete Example","title":"Problem Setup","text":"System: 3D oscillator with 2 control inputs\n\ndotx = (G_0 + u_1 G_1 + u_2 G_2) x\n\nGoal: Drive from [1, 0, 0] to [0, 0, 1] minimizing ∫ ||u||² dt + w·T\n\nConstraints: -1 ≤ u ≤ 1, 0.05 ≤ Δt ≤ 0.3","category":"section"},{"location":"generated/example/#Define-System-Dynamics","page":"Complete Example","title":"Define System Dynamics","text":"G_drift = [\n    0.0 1.0 0.0;\n    -1.0 0.0 0.0;\n    0.0 0.0 -0.1\n]\n\nG_drives = [\n    [\n        1.0 0.0 0.0;\n        0.0 0.0 0.0;\n        0.0 0.0 0.0\n    ],\n    [\n        0.0 0.0 0.0;\n        0.0 0.0 1.0;\n        0.0 1.0 0.0\n    ],\n]\n\nG = u -> G_drift + sum(u .* G_drives)","category":"section"},{"location":"generated/example/#Create-Trajectory","page":"Complete Example","title":"Create Trajectory","text":"N = 50\nx_init = [1.0, 0.0, 0.0]\nx_goal = [0.0, 0.0, 1.0]\nx_guess = hcat([x_init + (x_goal - x_init) * (k/(N-1)) for k = 0:(N-1)]...)\n\ntraj = NamedTrajectory(\n    (x = x_guess, u = 0.1 * randn(2, N), Δt = fill(0.15, N));\n    timestep = :Δt,\n    controls = (:u, :Δt),\n    initial = (x = x_init,),\n    final = (x = x_goal,),\n    bounds = (u = 1.0, Δt = (0.05, 0.3)),\n)","category":"section"},{"location":"generated/example/#Build-and-Solve-Problem","page":"Complete Example","title":"Build and Solve Problem","text":"integrator = BilinearIntegrator(G, :x, :u, traj)\n\nobj = (QuadraticRegularizer(:u, traj, 1.0) + 0.5 * MinimumTimeObjective(traj, 1.0))\n\nprob = DirectTrajOptProblem(traj, obj, integrator)\n\nprob\n\nsolve!(prob; max_iter = 50)","category":"section"},{"location":"generated/example/#Visualize-Solution","page":"Complete Example","title":"Visualize Solution","text":"plot(prob.trajectory) # See NamedTrajectories.jl documentation for plotting options","category":"section"},{"location":"generated/example/#Analyze-Solution","page":"Complete Example","title":"Analyze Solution","text":"x_sol = prob.trajectory.x\nu_sol = prob.trajectory.u\nΔt_sol = prob.trajectory.Δt\n\nprintln(\"Solution found!\")\nprintln(\"  Total time: $(sum(Δt_sol)) seconds\")\nprintln(\"  Δt range: [$(minimum(Δt_sol)), $(maximum(Δt_sol))]\")\nprintln(\"  Max |u₁|: $(maximum(abs.(u_sol[1,:])))\")\nprintln(\"  Max |u₂|: $(maximum(abs.(u_sol[2,:])))\")\nprintln(\"  Final error: $(norm(x_sol[:,end] - x_goal))\")","category":"section"},{"location":"generated/example/#Key-Insights","page":"Complete Example","title":"Key Insights","text":"Free time optimization: Variable Δt allows the optimizer to adjust trajectory speed, with shorter steps where control is needed and longer steps in smooth regions.\n\nControl bounds: With time weight 0.5, controls don't fully saturate. Increase the weight to push toward bang-bang control.\n\nCombined objectives: The + operator makes it easy to balance multiple goals.","category":"section"},{"location":"generated/example/#Exercises","page":"Complete Example","title":"Exercises","text":"1. Bang-bang control: Set time weight to 5.0 - do controls saturate the bounds?\n\n2. Fixed time: Remove Δt from controls and compare total time.\n\n3. Add waypoint: Require passing through [0.5, 0, 0.5] at the midpoint:\n\nconstraint = NonlinearKnotPointConstraint(\n    x -> x - [0.5, 0, 0.5], :x, traj;\n    times=[div(N,2)], equality=true\n)\nprob = DirectTrajOptProblem(traj, obj, integrator; constraints=[constraint])\n\n4. Different goal: Try reaching [0, 1, 0] or [0.5, 0.5, 0.5]\n\n5. Tighter bounds: Use bounds=(u = 0.5, Δt = (0.05, 0.3)) - how does time change?\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/concepts/constraints/#Constraints","page":"Constraints","title":"Constraints","text":"Constraints restrict the feasible region beyond dynamics. DirectTrajOpt supports bounds, boundary conditions, and nonlinear path constraints.\n\nusing DirectTrajOpt\nusing NamedTrajectories\nusing LinearAlgebra\n\nN = 50\ntraj = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n)","category":"section"},{"location":"generated/concepts/constraints/#Bounds-(Cheapest)","page":"Constraints","title":"Bounds (Cheapest)","text":"Box constraints on variables:\n\ntraj_bounds = NamedTrajectory(\n    (x = randn(2, N), u = randn(2, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (\n        x = 5.0,                          # -5 ≤ x ≤ 5\n        u = (-1.0, 2.0),                  # -1 ≤ u ≤ 2\n        Δt = (0.01, 0.5),                  # 0.01 ≤ Δt ≤ 0.5\n    ),\n)\n\nPer-component bounds:\n\ntraj_component_bounds = NamedTrajectory(\n    (x = randn(2, N), u = randn(2, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (u = ([-1.0, -2.0], [1.0, 3.0]),),  # Different bounds per component\n)","category":"section"},{"location":"generated/concepts/constraints/#Nonlinear-Constraints","page":"Constraints","title":"Nonlinear Constraints","text":"Inequality: c(x, u) ≥ 0 (preferred - easier to satisfy)\n\nconstraint_ineq = NonlinearKnotPointConstraint(\n    u -> [1.0 - norm(u)],  # ||u|| ≤ 1\n    :u,\n    traj;\n    times = 1:N,\n    equality = false,\n)\n\nEquality: c(x, u) = 0 (more restrictive)\n\nconstraint_eq = NonlinearKnotPointConstraint(\n    x -> [x[1] - 0.5],  # x₁ = 0.5\n    :x,\n    traj;\n    times = [25],\n    equality = true,\n)\n\nMultiple variables:\n\nconstraint_multi = NonlinearKnotPointConstraint(\n    (x, u) -> [x[1]^2 + x[2]^2 - u[1]],\n    [:x, :u],\n    traj;\n    equality = false,\n)","category":"section"},{"location":"generated/concepts/constraints/#Common-Patterns","page":"Constraints","title":"Common Patterns","text":"Obstacle avoidance:\n\nobs_center, obs_radius = [0.5, 0.5], 0.2\nconstraint_obstacle = NonlinearKnotPointConstraint(\n    x -> [norm(x - obs_center)^2 - obs_radius^2],\n    :x,\n    traj;\n    times = 1:N,\n    equality = false,\n)\n\nMultiple obstacles:\n\nconstraints_obstacles = [\n    NonlinearKnotPointConstraint(\n        x -> [norm(x - center)^2 - radius^2],\n        :x,\n        traj;\n        equality = false,\n    ) for (center, radius) in [([0.3, 0.3], 0.15), ([0.7, 0.7], 0.15)]\n]\n\nState-dependent control limits:\n\nconstraint_state_dep = NonlinearKnotPointConstraint(\n    (x, u) -> [1.0 - u[1] / (1.0 + abs(x[1]))],\n    [:x, :u],\n    traj;\n    equality = false,\n)\n\nEnergy constraints:\n\nE_max = 2.0\nconstraint_energy = NonlinearKnotPointConstraint(\n    (x, u) -> [E_max - (0.5 * norm(x)^2 + 0.5 * norm(u)^2)],\n    [:x, :u],\n    traj;\n    equality = false,\n)","category":"section"},{"location":"generated/concepts/constraints/#Time-Selection","page":"Constraints","title":"Time Selection","text":"All times, specific times, or ranges:\n\nconstraint_all = NonlinearKnotPointConstraint(\n    u -> [1.0 - norm(u)],\n    :u,\n    traj;\n    times = 1:N,\n    equality = false,\n)\n\nconstraint_specific = NonlinearKnotPointConstraint(\n    x -> [x[1]^2 + x[2]^2 - 1.0],\n    :x,\n    traj;\n    times = [1, 10, 20, 30, 40, 50],\n    equality = false,\n)\n\nconstraint_range = NonlinearKnotPointConstraint(\n    u -> [0.5 - norm(u)],\n    :u,\n    traj;\n    times = 10:40,\n    equality = false,\n)","category":"section"},{"location":"generated/concepts/constraints/#Creating-a-Problem","page":"Constraints","title":"Creating a Problem","text":"G_drift = [-0.1 1.0; -1.0 -0.1]\nG_drives = [[0.0 1.0; 1.0 0.0]]\nG = u -> G_drift + sum(u .* G_drives)\nintegrator = BilinearIntegrator(G, :x, :u, traj)\nobj = QuadraticRegularizer(:u, traj, 1.0)\n\nconstraints = [constraint_obstacle, constraint_ineq]\nprob = DirectTrajOptProblem(traj, obj, integrator; constraints = constraints)","category":"section"},{"location":"generated/concepts/constraints/#Summary","page":"Constraints","title":"Summary","text":"Constraint Type Form Cost Use Case\nBounds l ≤ v ≤ u Very cheap Physical limits\nDynamics xₖ₊₁ = Φ(xₖ, uₖ) Moderate System evolution\nBoundary x₁ = x₀, xₖ = xf Cheap Initial/final states\nNonlinear inequality c(x, u) ≥ 0 Moderate Obstacles, limits\nNonlinear equality c(x, u) = 0 Expensive Exact requirements","category":"section"},{"location":"generated/concepts/constraints/#Performance-Tips","page":"Constraints","title":"Performance Tips","text":"Recommendation Rationale\nUse bounds over nonlinear constraints Much faster to evaluate\nPrefer inequalities over equalities Easier to satisfy, larger feasible region\nScale constraint values to O(1) Better numerical conditioning\nAdd constraints incrementally Easier to debug, avoids over-constraining\nCheck initial guess feasibility Prevents infeasible starts","category":"section"},{"location":"generated/concepts/constraints/#Troubleshooting","page":"Constraints","title":"Troubleshooting","text":"If optimizer struggles:\n\nInfeasible start: Initial guess violates constraints → improve initial guess\nOver-constrained: Too many/conflicting constraints → relax or remove some\nPoorly scaled: Values span many orders of magnitude → rescale to O(1)\nTight constraints: Little feasible space → relax bounds or use soft constraints\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/bilinear_control/#Tutorial:-Bilinear-Control-with-Multiple-Drives","page":"Bilinear Control","title":"Tutorial: Bilinear Control with Multiple Drives","text":"This tutorial demonstrates a more complex bilinear control problem with:\n\nMultiple control inputs\nControl bounds\nA 3D state space","category":"section"},{"location":"generated/tutorials/bilinear_control/#Problem-Description","page":"Bilinear Control","title":"Problem Description","text":"Control a 3D system with 2 independent control inputs.\n\nDynamics:\n\ndotx = (G_0 + u_1 G_1 + u_2 G_2) x\n\nGoal: Navigate from [1, 0, 0] to [0, 0, 1] with bounded controls\n\nusing DirectTrajOpt\nusing NamedTrajectories\nusing LinearAlgebra\nusing Statistics\nusing Printf","category":"section"},{"location":"generated/tutorials/bilinear_control/#Step-1:-Define-the-System","page":"Bilinear Control","title":"Step 1: Define the System","text":"","category":"section"},{"location":"generated/tutorials/bilinear_control/#3D-System-with-Two-Drives","page":"Bilinear Control","title":"3D System with Two Drives","text":"Drift term - natural evolution\n\nG_drift = [\n    0.0 1.0 0.0;\n    -1.0 0.0 0.0;\n    0.0 0.0 -0.1\n]\n\nDrive terms - control influences\n\nG_drive_1 = [\n    1.0 0.0 0.0;\n    0.0 0.0 0.0;\n    0.0 0.0 0.0\n]  # Controls first state\n\nG_drive_2 = [\n    0.0 0.0 0.0;\n    0.0 0.0 1.0;\n    0.0 1.0 0.0\n]  # Controls coupling between states 2 and 3\n\nG_drives = [G_drive_1, G_drive_2]\n\nGenerator function\n\nG = u -> G_drift + sum(u .* G_drives)\n\nprintln(\"System dynamics:\")\nprintln(\"  State dimension: 3\")\nprintln(\"  Number of controls: 2\")\nprintln(\"  G_drift creates oscillation in x₁-x₂ plane with decay in x₃\")\nprintln(\"  u₁ drives x₁ component\")\nprintln(\"  u₂ couples x₂ and x₃\")","category":"section"},{"location":"generated/tutorials/bilinear_control/#Step-2:-Set-Up-the-Problem","page":"Bilinear Control","title":"Step 2: Set Up the Problem","text":"","category":"section"},{"location":"generated/tutorials/bilinear_control/#Time-Discretization","page":"Bilinear Control","title":"Time Discretization","text":"N = 60\nΔt = 0.15\ntotal_time = N * Δt\n\nprintln(\"\\nTime discretization:\")\nprintln(\"  Time steps: $N\")\nprintln(\"  Step size: $Δt\")\nprintln(\"  Total time: $total_time seconds\")","category":"section"},{"location":"generated/tutorials/bilinear_control/#Boundary-Conditions","page":"Bilinear Control","title":"Boundary Conditions","text":"x_init = [1.0, 0.0, 0.0]\nx_goal = [0.0, 0.0, 1.0]\n\nprintln(\"\\nBoundary conditions:\")\nprintln(\"  Initial state: $x_init\")\nprintln(\"  Goal state: $x_goal\")","category":"section"},{"location":"generated/tutorials/bilinear_control/#Initial-Guess","page":"Bilinear Control","title":"Initial Guess","text":"Linear interpolation for states\n\nx_guess = hcat([x_init + (x_goal - x_init) * (t/(N-1)) for t = 0:(N-1)]...)\n\nSmall random controls\n\nu_guess = 0.1 * randn(2, N)","category":"section"},{"location":"generated/tutorials/bilinear_control/#Step-3:-Create-Trajectory-with-Bounds","page":"Bilinear Control","title":"Step 3: Create Trajectory with Bounds","text":"Control bounds: -1 ≤ u ≤ 1 for both controls\n\ntraj = NamedTrajectory(\n    (x = x_guess, u = u_guess, Δt = fill(Δt, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = x_init,),\n    final = (x = x_goal,),\n    bounds = (u = 1.0,),  # -1 ≤ u ≤ 1\n)\n\nprintln(\"\\nTrajectory created:\")\nprintln(\"  Control bounds: \", traj.bounds.u)","category":"section"},{"location":"generated/tutorials/bilinear_control/#Step-4:-Define-Dynamics-and-Objective","page":"Bilinear Control","title":"Step 4: Define Dynamics and Objective","text":"Dynamics integrator\n\nintegrator = BilinearIntegrator(G, :x, :u, traj)\n\nObjective: minimize control effort\n\nR_u = 1.0  # control weight\nobj = QuadraticRegularizer(:u, traj, R_u)\n\nprintln(\"\\nObjective: minimize ∫ ||u||² dt\")\nprintln(\"  Control weight: $R_u\")","category":"section"},{"location":"generated/tutorials/bilinear_control/#Step-5:-Solve-the-Problem","page":"Bilinear Control","title":"Step 5: Solve the Problem","text":"prob = DirectTrajOptProblem(traj, obj, integrator)\n\nprob\n\nprintln(\"Solving optimization problem...\")\nprintln(\"=\"^50)\n\nsolve!(prob; max_iter = 150, verbose = false)\n\nprintln(\"=\"^50)\nprintln(\"Optimization complete!\")\nprintln(\"=\"^50)","category":"section"},{"location":"generated/tutorials/bilinear_control/#Step-6:-Analyze-the-Solution","page":"Bilinear Control","title":"Step 6: Analyze the Solution","text":"x_sol = prob.trajectory.x\nu_sol = prob.trajectory.u\ntimes = cumsum([0.0; prob.trajectory.Δt[:]])","category":"section"},{"location":"generated/tutorials/bilinear_control/#Goal-Reaching","page":"Bilinear Control","title":"Goal Reaching","text":"println(\"\\nGoal reaching:\")\nprintln(\"  Initial state: \", x_sol[:, 1])\nprintln(\"  Final state:   \", x_sol[:, end])\nprintln(\"  Goal state:    \", x_goal)\nprintln(\"  Final error:   \", norm(x_sol[:, end] - x_goal))","category":"section"},{"location":"generated/tutorials/bilinear_control/#Control-Statistics","page":"Bilinear Control","title":"Control Statistics","text":"println(\"\\nControl statistics:\")\nfor i = 1:2\n    u_i = u_sol[i, :]\n    println(\"  u$i:\")\n    println(\"    Max magnitude: \", maximum(abs.(u_i)))\n    println(\"    Mean magnitude: \", mean(abs.(u_i)))\n    println(\"    Total norm: \", norm(u_i))\n    # Check bound satisfaction\n    if all(-1.0 .<= u_i .<= 1.0)\n        println(\"    ✓ Bounds satisfied\")\n    else\n        println(\"    ✗ Bounds violated!\")\n    end\nend","category":"section"},{"location":"generated/tutorials/bilinear_control/#State-Trajectory-Analysis","page":"Bilinear Control","title":"State Trajectory Analysis","text":"println(\"\\nState trajectory:\")\nprintln(\"  Max |x₁|: \", maximum(abs.(x_sol[1, :])))\nprintln(\"  Max |x₂|: \", maximum(abs.(x_sol[2, :])))\nprintln(\"  Max |x₃|: \", maximum(abs.(x_sol[3, :])))","category":"section"},{"location":"generated/tutorials/bilinear_control/#Step-7:-Detailed-Results","page":"Bilinear Control","title":"Step 7: Detailed Results","text":"println(\"\\n\" * \"=\"^50)\nprintln(\"SOLUTION DETAILS\")\nprintln(\"=\"^50)\n\nprintln(\"\\nState trajectory (selected time points):\")\nprintln(\"Time  |   x₁    |   x₂    |   x₃\")\nprintln(\"-\"^40)\nfor k in [1, 10, 20, 30, 40, 50, N]\n    t = times[k]\n    println(\n        @sprintf(\"%.2f | %7.4f | %7.4f | %7.4f\", t, x_sol[1, k], x_sol[2, k], x_sol[3, k])\n    )\nend\n\nprintln(\"\\nControl trajectory (selected time points):\")\nprintln(\"Time  |   u₁    |   u₂\")\nprintln(\"-\"^30)\nfor k in [1, 10, 20, 30, 40, 50, N]\n    t = times[k]\n    println(@sprintf(\"%.2f | %7.4f | %7.4f\", t, u_sol[1, k], u_sol[2, k]))\nend","category":"section"},{"location":"generated/tutorials/bilinear_control/#Step-8:-Verify-Dynamics-Satisfaction","page":"Bilinear Control","title":"Step 8: Verify Dynamics Satisfaction","text":"println(\"\\nDynamics verification:\")\nmax_error = 0.0\nfor k = 1:(N-1)\n    global max_error\n    x_k = x_sol[:, k]\n    u_k = u_sol[:, k]\n    Δt_k = prob.trajectory.Δt[k]\n    # Predicted next state\n    x_k1_pred = exp(Δt_k * G(u_k)) * x_k\n    x_k1_actual = x_sol[:, k+1]\n    err = norm(x_k1_pred - x_k1_actual)\n    max_error = max(max_error, err)\nend\nprintln(\"  Maximum dynamics error: $max_error\")","category":"section"},{"location":"generated/tutorials/bilinear_control/#Comparison:-Different-Control-Weights","page":"Bilinear Control","title":"Comparison: Different Control Weights","text":"println(\"\\n\" * \"=\"^50)\nprintln(\"EXPLORING DIFFERENT CONTROL WEIGHTS\")\nprintln(\"=\"^50)\n\nTry with higher control penalty\n\ntraj_high = NamedTrajectory(\n    (x = x_guess, u = 0.1*randn(2, N), Δt = fill(Δt, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = x_init,),\n    final = (x = x_goal,),\n    bounds = (u = 1.0,),\n)\n\nobj_high = QuadraticRegularizer(:u, traj_high, 10.0)  # 10x larger weight\nintegrator_high = BilinearIntegrator(G, :x, :u, traj_high)\nprob_high = DirectTrajOptProblem(traj_high, obj_high, integrator_high)\n\nprintln(\"\\nSolving with high control weight (R=10.0)...\")\nsolve!(prob_high; max_iter = 150, verbose = false)\n\nu_sol_high = prob_high.trajectory.u\n\nprintln(\"\\nComparison:\")\nprintln(\"  Original (R=1.0):\")\nprintln(\"    ||u||: \", norm(u_sol))\nprintln(\"  High weight (R=10.0):\")\nprintln(\"    ||u||: \", norm(u_sol_high))\nprintln(\"  Control reduction: \", (1 - norm(u_sol_high)/norm(u_sol)) * 100, \"%\")","category":"section"},{"location":"generated/tutorials/bilinear_control/#Key-Observations","page":"Bilinear Control","title":"Key Observations","text":"Multiple controls allow independent actuation of different system modes\nBounds are strictly enforced — check that max|u| ≤ 1\nControl weight affects aggressiveness: lower weight produces larger controls that may saturate bounds, higher weight produces gentler controls\nInitial guess matters for bounded problems — random works here, but more complex problems may need better initialization\nBilinearIntegrator handles multi-input systems naturally — just provide all drive matrices in a vector","category":"section"},{"location":"generated/tutorials/bilinear_control/#Exercises","page":"Bilinear Control","title":"Exercises","text":"Try these modifications:","category":"section"},{"location":"generated/tutorials/bilinear_control/#Exercise-1:-Asymmetric-Bounds","page":"Bilinear Control","title":"Exercise 1: Asymmetric Bounds","text":"Set different bounds for each control:\n\nbounds=(u = ([-1.0, -0.5], [1.0, 2.0]),)","category":"section"},{"location":"generated/tutorials/bilinear_control/#Exercise-2:-Initial-Control-Constraints","page":"Bilinear Control","title":"Exercise 2: Initial Control Constraints","text":"Start and end with zero control:\n\ninitial=(x = x_init, u = [0.0, 0.0]),\nfinal=(x = x_goal, u = [0.0, 0.0])","category":"section"},{"location":"generated/tutorials/bilinear_control/#Exercise-3:-Intermediate-Waypoint","page":"Bilinear Control","title":"Exercise 3: Intermediate Waypoint","text":"Add a waypoint constraint at t=30:\n\nwaypoint = [0.5, 0.5, 0.5]\nconstraint = NonlinearKnotPointConstraint(\n    x -> x - waypoint, :x, traj;\n    times=[30], equality=true\n)","category":"section"},{"location":"generated/tutorials/bilinear_control/#Exercise-4:-Different-Goal","page":"Bilinear Control","title":"Exercise 4: Different Goal","text":"Try reaching [0, 1, 0] instead of [0, 0, 1]","category":"section"},{"location":"generated/tutorials/bilinear_control/#Exercise-5:-Add-Minimum-Time","page":"Bilinear Control","title":"Exercise 5: Add Minimum Time","text":"Make Δt variable and add MinimumTimeObjective:\n\nobj = QuadraticRegularizer(:u, traj, 1.0) +\n      MinimumTimeObjective(traj, 0.5)\nbounds=(u = 1.0, Δt = (0.05, 0.3))","category":"section"},{"location":"generated/tutorials/bilinear_control/#Next-Steps","page":"Bilinear Control","title":"Next Steps","text":"Minimum Time Tutorial: Optimize trajectory duration\nSmooth Controls Tutorial: Add derivative penalties for implementability\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/minimum_time/#Tutorial:-Minimum-Time-Problems","page":"Minimum Time","title":"Tutorial: Minimum Time Problems","text":"This tutorial shows how to solve time-optimal problems where trajectory duration is minimized alongside other objectives.","category":"section"},{"location":"generated/tutorials/minimum_time/#Problem-Description","page":"Minimum Time","title":"Problem Description","text":"Find the fastest trajectory from start to goal with bounded controls.\n\nDynamics:\n\ndotx = (G_0 + u_1 G_1) x\n\nObjective: Minimize total time + control effort\n\nConstraints: |u| ≤ 1\n\nusing DirectTrajOpt\nusing NamedTrajectories\nusing LinearAlgebra\nusing Statistics\nusing Printf","category":"section"},{"location":"generated/tutorials/minimum_time/#Fixed-Time-vs-Free-Time","page":"Minimum Time","title":"Fixed Time vs Free Time","text":"println(\"=\"^50)\nprintln(\"MINIMUM TIME TRAJECTORY OPTIMIZATION\")\nprintln(\"=\"^50)\n\nprintln(\"\"\"\nTwo approaches:\n1. **Fixed time**: All Δt equal and constant\n2. **Free time**: Each Δt is a variable (what we'll use)\n\nFree time allows the optimizer to adjust trajectory duration.\n\"\"\")","category":"section"},{"location":"generated/tutorials/minimum_time/#Step-1:-System-Definition","page":"Minimum Time","title":"Step 1: System Definition","text":"G_drift = [\n    -0.1 1.0;\n    -1.0 -0.1\n]\n\nG_drives = [[\n    0.0 1.0;\n    1.0 0.0\n]]\n\nG = u -> G_drift + sum(u .* G_drives)\n\nprintln(\"System: 2D damped oscillator with symmetric control coupling\")","category":"section"},{"location":"generated/tutorials/minimum_time/#Step-2:-Trajectory-Setup","page":"Minimum Time","title":"Step 2: Trajectory Setup","text":"N = 40# Number of time steps (fewer than before)\nΔt_init = 0.15  # Initial guess for time step\n\nx_init = [0.0, 0.0]\nx_goal = [1.0, 0.0]\n\nInitial guess\n\nx_guess = hcat([x_init + (x_goal - x_init) * (t/(N-1)) for t = 0:(N-1)]...)\nu_guess = 0.1 * randn(1, N)\nΔt_guess = fill(Δt_init, N)\n\nprintln(\"\\nProblem setup:\")\nprintln(\"  Time steps: $N\")\nprintln(\"  Initial guess for Δt: $Δt_init\")\nprintln(\"  Initial total time: \", sum(Δt_guess))","category":"section"},{"location":"generated/tutorials/minimum_time/#Step-3:-Create-Free-Time-Trajectory","page":"Minimum Time","title":"Step 3: Create Free-Time Trajectory","text":"Key: timestep=:Δt makes time steps decision variables\n\ntraj_mintime = NamedTrajectory(\n    (x = x_guess, u = u_guess, Δt = Δt_guess);\n    timestep = :Δt,  # Time is a variable!\n    controls = :u,\n    initial = (x = x_init,),\n    final = (x = x_goal,),\n    bounds = (\n        u = 1.0,            # -1 ≤ u ≤ 1\n        Δt = (0.01, 0.5),    # 0.01 ≤ Δt ≤ 0.5\n    ),\n)\n\nprintln(\"\\nTrajectory bounds:\")\nprintln(\"  Control: \", traj_mintime.bounds.u)\nprintln(\"  Time step: \", traj_mintime.bounds.Δt)","category":"section"},{"location":"generated/tutorials/minimum_time/#Step-4:-Define-Objectives","page":"Minimum Time","title":"Step 4: Define Objectives","text":"","category":"section"},{"location":"generated/tutorials/minimum_time/#Time-Minimization-Weight","page":"Minimum Time","title":"Time Minimization Weight","text":"The key parameter: balance speed vs control effort\n\nw_time = 1.0   # Weight on total time\nw_control = 1e-2  # Weight on control effort\n\nobj_mintime = (\n    w_control * QuadraticRegularizer(:u, traj_mintime, 1.0) +\n    w_time * MinimumTimeObjective(traj_mintime, 1.0)\n)\n\nprintln(\"\\nObjective weights:\")\nprintln(\"  Control effort: $w_control\")\nprintln(\"  Time: $w_time\")\nprintln(\"  → Emphasizes minimizing time\")","category":"section"},{"location":"generated/tutorials/minimum_time/#Step-5:-Solve-Minimum-Time-Problem","page":"Minimum Time","title":"Step 5: Solve Minimum Time Problem","text":"integrator_mintime = BilinearIntegrator(G, :x, :u, traj_mintime)\nprob_mintime = DirectTrajOptProblem(traj_mintime, obj_mintime, integrator_mintime)\n\nprob_mintime\n\nprintln(\"Solving minimum time problem...\")\nprintln(\"=\"^50)\n\nsolve!(prob_mintime; max_iter = 200, verbose = false)\n\nprintln(\"=\"^50)\nprintln(\"Minimum time solution found!\")\nprintln(\"=\"^50)","category":"section"},{"location":"generated/tutorials/minimum_time/#Step-6:-Analyze-Time-Optimal-Solution","page":"Minimum Time","title":"Step 6: Analyze Time-Optimal Solution","text":"x_sol_mintime = prob_mintime.trajectory.x\nu_sol_mintime = prob_mintime.trajectory.u\nΔt_sol_mintime = prob_mintime.trajectory.Δt\n\ntotal_time_mintime = sum(Δt_sol_mintime)\n\nprintln(\"\\nMinimum time solution:\")\nprintln(\"  Total time: $total_time_mintime seconds\")\nprintln(\"  Average Δt: \", mean(Δt_sol_mintime))\nprintln(\"  Min Δt: \", minimum(Δt_sol_mintime))\nprintln(\"  Max Δt: \", maximum(Δt_sol_mintime))\n\nprintln(\"\\nControl statistics:\")\nprintln(\"  Max |u|: \", maximum(abs.(u_sol_mintime)))\nprintln(\"  Mean |u|: \", mean(abs.(u_sol_mintime)))\nprintln(\"  ||u||: \", norm(u_sol_mintime))\n\nCheck if controls saturate\n\nu_saturated = sum(abs.(u_sol_mintime) .> 0.99)\nprintln(\"  Time steps with |u| > 0.99: $u_saturated / $N\")","category":"section"},{"location":"generated/tutorials/minimum_time/#Step-7:-Comparison-with-Fixed-Time-Solution","page":"Minimum Time","title":"Step 7: Comparison with Fixed-Time Solution","text":"println(\"\\n\" * \"=\"^50)\nprintln(\"COMPARISON: MINIMUM TIME vs FIXED TIME\")\nprintln(\"=\"^50)\n\nSolve fixed-time problem with same total time\n\nΔt_fixed = total_time_mintime / N\n\ntraj_fixed = NamedTrajectory(\n    (x = x_guess, u = u_guess, Δt = fill(Δt_fixed, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = x_init,),\n    final = (x = x_goal,),\n    bounds = (u = 1.0,),\n)\n\nobj_fixed = QuadraticRegularizer(:u, traj_fixed, 1.0)\nintegrator_fixed = BilinearIntegrator(G, :x, :u, traj_fixed)\nprob_fixed = DirectTrajOptProblem(traj_fixed, obj_fixed, integrator_fixed)\n\nprintln(\"\\nSolving fixed-time problem with T = $total_time_mintime seconds...\")\nsolve!(prob_fixed; max_iter = 150, verbose = false)\n\nu_sol_fixed = prob_fixed.trajectory.u\n\nprintln(\"\\nComparison:\")\nprintln(\"  Minimum time:\")\nprintln(\"    Total time: $total_time_mintime s\")\nprintln(\"    ||u||: \", norm(u_sol_mintime))\nprintln(\"    Max |u|: \", maximum(abs.(u_sol_mintime)))\nprintln(\"  Fixed time:\")\nprintln(\"    Total time: \", sum(prob_fixed.trajectory.Δt), \" s\")\nprintln(\"    ||u||: \", norm(u_sol_fixed))\nprintln(\"    Max |u|: \", maximum(abs.(u_sol_fixed)))","category":"section"},{"location":"generated/tutorials/minimum_time/#Step-8:-Effect-of-Time-Weight","page":"Minimum Time","title":"Step 8: Effect of Time Weight","text":"println(\"\\n\" * \"=\"^50)\nprintln(\"EXPLORING TIME WEIGHT EFFECTS\")\nprintln(\"=\"^50)\n\nTry different time weights\n\ntime_weights = [0.1, 1.0, 10.0]\nresults = []\n\nfor w_t in time_weights\n    traj_test = NamedTrajectory(\n        (x = x_guess, u = u_guess, Δt = Δt_guess);\n        timestep = :Δt,\n        controls = :u,\n        initial = (x = x_init,),\n        final = (x = x_goal,),\n        bounds = (u = 1.0, Δt = (0.01, 0.5)),\n    )\n\n    obj_test = (\n        1e-2 * QuadraticRegularizer(:u, traj_test, 1.0) +\n        w_t * MinimumTimeObjective(traj_test, 1.0)\n    )\n\n    integrator_test = BilinearIntegrator(G, :x, :u, traj_test)\n    prob_test = DirectTrajOptProblem(traj_test, obj_test, integrator_test)\n\n    solve!(prob_test; max_iter = 200, verbose = false)\n\n    push!(\n        results,\n        (\n            weight = w_t,\n            time = sum(prob_test.trajectory.Δt),\n            control_norm = norm(prob_test.trajectory.u),\n            max_control = maximum(abs.(prob_test.trajectory.u)),\n        ),\n    )\nend\n\nprintln(\"\\nTime weight effects:\")\nprintln(\"Weight | Total Time | ||u||   | Max |u|\")\nprintln(\"-\"^45)\nfor r in results\n    println(\n        @sprintf(\n            \"%.1f   | %.4f s   | %.4f | %.4f\",\n            r.weight,\n            r.time,\n            r.control_norm,\n            r.max_control\n        )\n    )\nend\n\nprintln(\"\\nObservations:\")\nprintln(\"  - Lower weight → slower trajectory, gentler controls\")\nprintln(\"  - Higher weight → faster trajectory, more aggressive controls\")","category":"section"},{"location":"generated/tutorials/minimum_time/#Step-9:-Time-Step-Adaptation","page":"Minimum Time","title":"Step 9: Time Step Adaptation","text":"Δt_variation = std(Δt_sol_mintime)\nprintln(\"\\nTime step adaptation:\")\nprintln(\"  Std dev(Δt): \", Δt_variation)\nprintln(\n    \"  Coefficient of variation: \",\n    @sprintf(\"%.3f\", Δt_variation / mean(Δt_sol_mintime))\n)","category":"section"},{"location":"generated/tutorials/minimum_time/#Key-Insights","page":"Minimum Time","title":"Key Insights","text":"Free time variables: Setting timestep=:Δt makes time steps optimizable\nTime bounds are crucial: Lower bound prevents Δt -> 0, upper bound prevents unrealistically large steps\nTime weight balances speed vs control: High weight -> fast but aggressive, low weight -> slow but gentle\nControl saturation: Time-optimal solutions often saturate control bounds (bang-bang behavior)\nNon-uniform time steps: Optimizer may choose variable Δt — larger steps where less control is needed\nInitial guess: Start with reasonable Δt to help convergence","category":"section"},{"location":"generated/tutorials/minimum_time/#Best-Practices","page":"Minimum Time","title":"Best Practices","text":"","category":"section"},{"location":"generated/tutorials/minimum_time/#Time-Step-Bounds","page":"Minimum Time","title":"Time Step Bounds","text":"Lower bound: ~0.01 to 0.05 (prevent numerical issues)\nUpper bound: 1/10 to 1/5 of expected total time\nStart conservative, relax if needed","category":"section"},{"location":"generated/tutorials/minimum_time/#Control-Weights","page":"Minimum Time","title":"Control Weights","text":"Usually small (1e-3 to 1e-2) for regularization\nJust enough to ensure well-conditioned problem\nToo large defeats the purpose of time minimization","category":"section"},{"location":"generated/tutorials/minimum_time/#Time-Weights","page":"Minimum Time","title":"Time Weights","text":"Start with ~1.0 and adjust\nIncrease to prioritize speed more\nDecrease if controls become too aggressive","category":"section"},{"location":"generated/tutorials/minimum_time/#Number-of-Time-Steps","page":"Minimum Time","title":"Number of Time Steps","text":"Fewer steps = less resolution, harder to satisfy dynamics\nMore steps = more variables, slower solve\nRule of thumb: 30-100 steps for most problems","category":"section"},{"location":"generated/tutorials/minimum_time/#Initialization","page":"Minimum Time","title":"Initialization","text":"Use solution from fixed-time problem as warm start\nOr solve with high control weight first, then reduce","category":"section"},{"location":"generated/tutorials/minimum_time/#Exercises","page":"Minimum Time","title":"Exercises","text":"","category":"section"},{"location":"generated/tutorials/minimum_time/#Exercise-1:-Bang-Bang-Control","page":"Minimum Time","title":"Exercise 1: Bang-Bang Control","text":"Increase time weight to w_time=100.0. Do controls saturate more?","category":"section"},{"location":"generated/tutorials/minimum_time/#Exercise-2:-Time-Step-Constraints","page":"Minimum Time","title":"Exercise 2: Time Step Constraints","text":"Try tighter bounds: Δt ∈ [0.05, 0.15]. How does total time change?","category":"section"},{"location":"generated/tutorials/minimum_time/#Exercise-3:-Longer-Distance","page":"Minimum Time","title":"Exercise 3: Longer Distance","text":"Change goal to x_goal = [2.0, 0.0]. How does optimal time scale?","category":"section"},{"location":"generated/tutorials/minimum_time/#Exercise-4:-Multiple-Objectives","page":"Minimum Time","title":"Exercise 4: Multiple Objectives","text":"Add terminal cost with soft goal:\n\nobj = w_control * QuadraticRegularizer(:u, traj, 1.0) +\n      w_time * MinimumTimeObjective(traj, 1.0) +\n      100.0 * TerminalObjective(x -> norm(x - x_goal)^2, :x, traj)","category":"section"},{"location":"generated/tutorials/minimum_time/#Exercise-5:-Warm-Starting","page":"Minimum Time","title":"Exercise 5: Warm Starting","text":"Solve fixed-time problem first, use as initial guess for free-time:\n\ntraj_warm = NamedTrajectory(\n    (x = prob_fixed.trajectory.x,\n     u = prob_fixed.trajectory.u,\n     Δt = Δt_guess);\n    # ... rest of setup\n)","category":"section"},{"location":"generated/tutorials/minimum_time/#Next-Steps","page":"Minimum Time","title":"Next Steps","text":"Smooth Controls Tutorial: Add derivative penalties while minimizing time\nHow-To Guide: Tune the Solver: Improve convergence for difficult problems\nAdvanced Topics: Performance: Optimize large-scale problems\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/concepts/objectives/#Objectives","page":"Objectives","title":"Objectives","text":"","category":"section"},{"location":"generated/concepts/objectives/#What-are-Objectives?","page":"Objectives","title":"What are Objectives?","text":"Objectives (or cost functions) define what you want to minimize in your optimization problem. DirectTrajOpt.jl uses an additive structure where you can combine multiple objective terms:\n\nJ_texttotal = w_1 J_1 + w_2 J_2 + cdots + w_N J_N\n\nusing DirectTrajOpt\nusing NamedTrajectories\nusing LinearAlgebra\n\nSetup a sample trajectory for examples\n\nN = 50\ntraj = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = [0.0, 0.0],),\n    goal = (x = [1.0, 0.0],),\n)","category":"section"},{"location":"generated/concepts/objectives/#QuadraticRegularizer","page":"Objectives","title":"QuadraticRegularizer","text":"","category":"section"},{"location":"generated/concepts/objectives/#Overview","page":"Objectives","title":"Overview","text":"Penalizes the squared norm of a variable:\n\nJ = sum_k=1^N v_k^2\n\nThis is the most common objective for regularization.","category":"section"},{"location":"generated/concepts/objectives/#Control-Effort-Regularization","page":"Objectives","title":"Control Effort Regularization","text":"obj_u = QuadraticRegularizer(:u, traj, 1.0)\n\nMinimizes: Σₖ ||uₖ||²","category":"section"},{"location":"generated/concepts/objectives/#State-Regularization","page":"Objectives","title":"State Regularization","text":"obj_x = QuadraticRegularizer(:x, traj, 0.1)\n\nMinimizes: 0.1 * Σₖ ||xₖ||²","category":"section"},{"location":"generated/concepts/objectives/#Control-Derivative-Regularization-(Smoothness)","page":"Objectives","title":"Control Derivative Regularization (Smoothness)","text":"traj_smooth = NamedTrajectory(\n    (x = randn(2, N), u = randn(2, N), du = zeros(2, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n)\n\nobj_du = QuadraticRegularizer(:du, traj_smooth, 1.0)\n\nMinimizes: Σₖ ||duₖ||² (encourages smooth controls)","category":"section"},{"location":"generated/concepts/objectives/#Combining-Regularizers","page":"Objectives","title":"Combining Regularizers","text":"Typical combination: control effort + smoothness\n\nobj_combined =\n    QuadraticRegularizer(:u, traj_smooth, 1e-2) +\n    QuadraticRegularizer(:du, traj_smooth, 1e-1)\n\nSmall control penalty, larger smoothness penalty","category":"section"},{"location":"generated/concepts/objectives/#Per-Component-Weights","page":"Objectives","title":"Per-Component Weights","text":"You can weight each component differently:\n\nobj_weighted = QuadraticRegularizer(:u, traj_smooth, [1.0, 0.5])\n\nFirst control component weighted more heavily","category":"section"},{"location":"generated/concepts/objectives/#MinimumTimeObjective","page":"Objectives","title":"MinimumTimeObjective","text":"","category":"section"},{"location":"generated/concepts/objectives/#Overview-2","page":"Objectives","title":"Overview","text":"Minimizes the total trajectory duration:\n\nJ = w sum_k=1^N Delta t_k\n\nThis encourages fast trajectories.","category":"section"},{"location":"generated/concepts/objectives/#Basic-Usage","page":"Objectives","title":"Basic Usage","text":"obj_time = MinimumTimeObjective(traj, 0.1)\n\nMinimizes: 0.1 * Σₖ Δtₖ","category":"section"},{"location":"generated/concepts/objectives/#Time-Energy-Tradeoff","page":"Objectives","title":"Time-Energy Tradeoff","text":"Combine with control regularization to trade off speed vs effort:\n\nobj_tradeoff = QuadraticRegularizer(:u, traj, 1.0) + MinimumTimeObjective(traj, 0.5)\n\nHigher time weight → faster but more control effort Lower time weight → slower but less control effort","category":"section"},{"location":"generated/concepts/objectives/#Free-Time-Problems","page":"Objectives","title":"Free Time Problems","text":"traj_free_time = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (Δt = (0.01, 0.5),),  # Allow variable time steps\n)\n\nobj_free_time =\n    QuadraticRegularizer(:u, traj_free_time, 1.0) +\n    MinimumTimeObjective(traj_free_time, 1.0)","category":"section"},{"location":"generated/concepts/objectives/#TerminalObjective","page":"Objectives","title":"TerminalObjective","text":"","category":"section"},{"location":"generated/concepts/objectives/#Overview-3","page":"Objectives","title":"Overview","text":"Applies a cost only at the final time step:\n\nJ = f(x_N)\n\nUseful for soft constraints on the final state.","category":"section"},{"location":"generated/concepts/objectives/#Distance-to-Goal","page":"Objectives","title":"Distance to Goal","text":"x_goal = [1.0, 0.0]\nobj_terminal = TerminalObjective(x -> norm(x - x_goal)^2, :x, traj)\n\nPenalizes: ||xN - xgoal||²","category":"section"},{"location":"generated/concepts/objectives/#Custom-Terminal-Cost","page":"Objectives","title":"Custom Terminal Cost","text":"Any function of the final state:\n\nobj_custom_terminal = TerminalObjective(x -> x[1]^2 + 2*x[2]^2 + x[1]*x[2], :x, traj)","category":"section"},{"location":"generated/concepts/objectives/#When-to-Use","page":"Objectives","title":"When to Use","text":"Soft goal: Don't enforce exact final state, just penalize deviation\nMultiple goals: Can have terminal costs on multiple variables\nCustom metrics: Use domain-specific final state metrics","category":"section"},{"location":"generated/concepts/objectives/#Hard-vs-Soft-Constraints","page":"Objectives","title":"Hard vs Soft Constraints","text":"Hard constraint (via trajectory):\n\ntraj_hard = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    final = (x = x_goal,),  # Exact constraint\n)\n\nSoft constraint (via terminal objective):\n\ntraj_soft = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    goal = (x = x_goal,),  # For reference only\n)\nobj_soft = TerminalObjective(x -> 100.0 * norm(x - x_goal)^2, :x, traj_soft)\n\nLarge weight approximates hard constraint","category":"section"},{"location":"generated/concepts/objectives/#KnotPointObjective","page":"Objectives","title":"KnotPointObjective","text":"","category":"section"},{"location":"generated/concepts/objectives/#Overview-4","page":"Objectives","title":"Overview","text":"Applies a cost at specific time steps:\n\nJ = sum_k in K f(x_k u_k)\n\nUseful for waypoints or intermediate constraints.","category":"section"},{"location":"generated/concepts/objectives/#Single-Time-Point","page":"Objectives","title":"Single Time Point","text":"obj_knot_single = KnotPointObjective(\n    x -> norm(x - [0.5, 0.5])^2,\n    :x,\n    traj;\n    times = [25],  # Only at k=25\n)","category":"section"},{"location":"generated/concepts/objectives/#Multiple-Time-Points","page":"Objectives","title":"Multiple Time Points","text":"obj_knot_multi = KnotPointObjective(\n    u -> norm(u)^2,\n    :u,\n    traj;\n    times = [10, 20, 30, 40],  # At k=10, 20, 30, 40\n)","category":"section"},{"location":"generated/concepts/objectives/#All-Time-Points-(Path-Cost)","page":"Objectives","title":"All Time Points (Path Cost)","text":"obj_knot_all = KnotPointObjective(\n    xu -> xu[1]^2 + xu[3]^2,  # xu is concatenated [x; u]\n    [:x, :u],\n    traj;\n    times = 1:N,  # All time steps\n)\n\nEquivalent to manually summing costs","category":"section"},{"location":"generated/concepts/objectives/#Waypoint-Tracking","page":"Objectives","title":"Waypoint Tracking","text":"waypoints = [\n    [0.25, 0.25],  # k=13\n    [0.75, 0.75],  # k=38\n]\nwaypoint_times = [13, 38]\n\nobj_waypoints = sum(\n    KnotPointObjective(x -> 10.0 * norm(x - wp)^2, :x, traj; times = [t]) for\n    (wp, t) in zip(waypoints, waypoint_times)\n)","category":"section"},{"location":"generated/concepts/objectives/#GlobalObjective","page":"Objectives","title":"GlobalObjective","text":"","category":"section"},{"location":"generated/concepts/objectives/#Overview-5","page":"Objectives","title":"Overview","text":"Applies a cost to global variables (constants across time):\n\nJ = f(g)\n\nUseful for parameters, scaling factors, or other time-independent variables.","category":"section"},{"location":"generated/concepts/objectives/#Example-with-Global-Parameter","page":"Objectives","title":"Example with Global Parameter","text":"traj_global = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    global_data = [1.0],  # Global parameter\n    global_components = (α = 1:1,),\n)\n\nobj_global = GlobalObjective(\n    α -> (α[1] - 2.0)^2,  # Penalize α deviating from 2\n    :α,\n    traj_global,\n)","category":"section"},{"location":"generated/concepts/objectives/#Combining-Objectives","page":"Objectives","title":"Combining Objectives","text":"","category":"section"},{"location":"generated/concepts/objectives/#Addition-Operator","page":"Objectives","title":"Addition Operator","text":"The + operator combines objectives:\n\nobj1 = QuadraticRegularizer(:u, traj, 1.0)\nobj2 = MinimumTimeObjective(traj, 0.1)\nobj3 = TerminalObjective(x -> norm(x - x_goal)^2, :x, traj)\n\nobj_total = obj1 + obj2 + obj3","category":"section"},{"location":"generated/concepts/objectives/#Weighting-Strategy","page":"Objectives","title":"Weighting Strategy","text":"Common pattern: regularization + task objective + time\n\nobj_pattern = (\n    1e-2 * QuadraticRegularizer(:u, traj, 1.0) +      # Small control penalty\n    1e-1 * MinimumTimeObjective(traj, 1.0) +          # Moderate time penalty\n    1e2 * TerminalObjective(                          # Large goal penalty\n        x -> norm(x - x_goal)^2,\n        :x,\n        traj,\n    )\n)","category":"section"},{"location":"generated/concepts/objectives/#Building-Incrementally","page":"Objectives","title":"Building Incrementally","text":"obj_build = QuadraticRegularizer(:u, traj, 1.0)\n\nAdd time minimization\n\nobj_build += MinimumTimeObjective(traj, 0.1)\n\nAdd terminal cost\n\nobj_build += TerminalObjective(x -> norm(x - x_goal)^2, :x, traj)","category":"section"},{"location":"generated/concepts/objectives/#Objective-Design-Patterns","page":"Objectives","title":"Objective Design Patterns","text":"","category":"section"},{"location":"generated/concepts/objectives/#Pattern-1:-Pure-Tracking","page":"Objectives","title":"Pattern 1: Pure Tracking","text":"Minimize deviation from goal at final time\n\nobj_tracking = TerminalObjective(x -> norm(x - x_goal)^2, :x, traj)","category":"section"},{"location":"generated/concepts/objectives/#Pattern-2:-Energy-Optimal","page":"Objectives","title":"Pattern 2: Energy-Optimal","text":"Minimize control effort with soft goal\n\nobj_energy = (\n    QuadraticRegularizer(:u, traj, 1.0) +\n    10.0 * TerminalObjective(x -> norm(x - x_goal)^2, :x, traj)\n)","category":"section"},{"location":"generated/concepts/objectives/#Pattern-3:-Minimum-Time","page":"Objectives","title":"Pattern 3: Minimum-Time","text":"Fast trajectories with bounded controls\n\ntraj_mintime = NamedTrajectory(\n    (x = randn(2, N), u = randn(1, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    bounds = (u = 1.0, Δt = (0.01, 0.5)),\n)\n\nobj_mintime = (\n    1e-3 * QuadraticRegularizer(:u, traj_mintime, 1.0) +  # Small regularization\n    1.0 * MinimumTimeObjective(traj_mintime, 1.0) +       # Minimize time\n    100.0 * TerminalObjective(                            # Strong goal\n        x -> norm(x - x_goal)^2,\n        :x,\n        traj_mintime,\n    )\n)","category":"section"},{"location":"generated/concepts/objectives/#Pattern-4:-Smooth-Control","page":"Objectives","title":"Pattern 4: Smooth Control","text":"Implementable controls with derivative penalties\n\ntraj_smooth_obj = NamedTrajectory(\n    (x = randn(2, N), u = randn(2, N), du = zeros(2, N), Δt = fill(0.1, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (u = [0.0, 0.0],),\n    final = (u = [0.0, 0.0],),\n)\n\nobj_smooth_pattern = (\n    1e-2 * QuadraticRegularizer(:u, traj_smooth_obj, 1.0) +   # Control effort\n    1e-1 * QuadraticRegularizer(:du, traj_smooth_obj, 1.0) +  # Smoothness\n    10.0 * TerminalObjective(x -> norm(x - x_goal)^2, :x, traj_smooth_obj)\n)","category":"section"},{"location":"generated/concepts/objectives/#Pattern-5:-Waypoint-Following","page":"Objectives","title":"Pattern 5: Waypoint Following","text":"Hit intermediate points along trajectory\n\nobj_waypoint_pattern = (\n    QuadraticRegularizer(:u, traj, 1.0) +\n    obj_waypoints +  # From earlier example\n    TerminalObjective(x -> norm(x - x_goal)^2, :x, traj)\n)","category":"section"},{"location":"generated/concepts/objectives/#Weight-Tuning-Guidelines","page":"Objectives","title":"Weight Tuning Guidelines","text":"","category":"section"},{"location":"generated/concepts/objectives/#Relative-Magnitudes","page":"Objectives","title":"Relative Magnitudes","text":"Regularization: 1e-3 to 1e-1 (small, for smoothness/stability)\nTask objectives: 1e0 to 1e2 (primary goal)\nHard constraints via penalties: 1e2 to 1e4 (large, approximate hard constraints)","category":"section"},{"location":"generated/concepts/objectives/#Balancing-Tradeoffs","page":"Objectives","title":"Balancing Tradeoffs","text":"# Fast, aggressive controls\nobj = 1e-4 * QuadraticRegularizer(:u, traj, 1.0) + MinimumTimeObjective(traj, 1.0)\n\n# Slow, gentle controls\nobj = 1e0 * QuadraticRegularizer(:u, traj, 1.0) + 1e-2 * MinimumTimeObjective(traj, 1.0)","category":"section"},{"location":"generated/concepts/objectives/#Iterative-Tuning","page":"Objectives","title":"Iterative Tuning","text":"Start with task objective only\nAdd regularization if needed for stability\nAdjust weights based on results\nUse solver output to guide adjustments","category":"section"},{"location":"generated/concepts/objectives/#Custom-Objectives","page":"Objectives","title":"Custom Objectives","text":"You can create custom objectives by implementing the Objective interface. All objectives must define how they contribute to the cost and its gradients.","category":"section"},{"location":"generated/concepts/objectives/#Example-Structure-(Conceptual)","page":"Objectives","title":"Example Structure (Conceptual)","text":"# Custom objective for special cost\nmy_obj = CustomObjective(params...)\n\n# Add to problem\nobj = QuadraticRegularizer(:u, traj, 1.0) + my_obj\n\nSee the API Reference for details on implementing custom objectives.","category":"section"},{"location":"generated/concepts/objectives/#Summary","page":"Objectives","title":"Summary","text":"Objective Type Use Case Typical Weight\nQuadraticRegularizer Control effort, smoothness 1e-3 to 1e-1\nMinimumTimeObjective Fast trajectories 1e-2 to 1e0\nTerminalObjective Goal reaching 1e0 to 1e2\nKnotPointObjective Waypoints, path costs 1e0 to 1e1\nGlobalObjective Parameter penalties Problem-specific","category":"section"},{"location":"generated/concepts/objectives/#Best-Practices","page":"Objectives","title":"Best Practices","text":"Start simple: Use basic regularization + terminal cost first\nScale consistently: Keep objective terms of similar magnitude\nUse soft constraints: Prefer high-weight objectives over hard constraints when possible\nMonitor convergence: Check if optimizer struggles with certain objectives\nIterative refinement: Adjust weights based on results","category":"section"},{"location":"generated/concepts/objectives/#Next-Steps","page":"Objectives","title":"Next Steps","text":"Constraints: Learn about bounds and path constraints\nTutorials: See complete examples with combined objectives\nProblem Setup: Put it all together to solve optimization problems\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/tutorials/linear_system/#Tutorial:-Linear-System-Control","page":"Linear System","title":"Tutorial: Linear System Control","text":"In this tutorial, we'll solve a simple 2D linear control problem from start to finish.","category":"section"},{"location":"generated/tutorials/linear_system/#Problem-Description","page":"Linear System","title":"Problem Description","text":"We want to control a 2D oscillator from rest at the origin to a target position, minimizing control effort.\n\nSystem dynamics:\n\ndotx = (G_0 + u_1 G_1) x\n\nGoal: Drive from x(0) = [0, 0] to x(N) = [1, 0]\n\nObjective: Minimize control effort ∫ ||u||² dt\n\nusing DirectTrajOpt\nusing NamedTrajectories\nusing LinearAlgebra\nusing Statistics\nusing Printf","category":"section"},{"location":"generated/tutorials/linear_system/#Step-1:-Define-the-System-Dynamics","page":"Linear System","title":"Step 1: Define the System Dynamics","text":"The drift matrix (natural dynamics):\n\nG_drift = [\n    -0.1 1.0;\n    -1.0 -0.1\n]\n\nThe drive matrix (control influence):\n\nG_drives = [[\n    0.0 1.0;\n    1.0 0.0\n]]\n\nGenerator function:\n\nG = u -> G_drift + sum(u .* G_drives)\n\nLet's understand what this system does:\n\nG_drift creates damped oscillations\nG_drives couples the two states symmetrically\nControl u affects how the states influence each other","category":"section"},{"location":"generated/tutorials/linear_system/#Step-2:-Create-the-Trajectory","page":"Linear System","title":"Step 2: Create the Trajectory","text":"Time parameters\n\nN = 50# number of time steps\nΔt = 0.1        # time step size\ntotal_time = N * Δt  # 5 seconds\n\nprintln(\"Total time: $total_time seconds\")\n\nInitial and goal states\n\nx_init = [0.0, 0.0]\nx_goal = [1.0, 0.0]\n\nCreate initial guess with linear interpolation\n\nx_guess = hcat([x_init + (x_goal - x_init) * (t/(N-1)) for t = 0:(N-1)]...)\nu_guess = zeros(1, N)\n\nCreate the trajectory\n\ntraj = NamedTrajectory(\n    (x = x_guess, u = u_guess, Δt = fill(Δt, N));\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = x_init,),\n    final = (x = x_goal,),\n)\n\nprintln(\"Trajectory dimensions:\")\nprintln(\"  States: \", traj.dims.x)\nprintln(\"  Controls: \", traj.dims.u)\nprintln(\"  Time steps: \", traj.N)","category":"section"},{"location":"generated/tutorials/linear_system/#Step-3:-Define-the-Dynamics-Constraint","page":"Linear System","title":"Step 3: Define the Dynamics Constraint","text":"Use BilinearIntegrator for our control-linear system:\n\nintegrator = BilinearIntegrator(G, :x, :u, traj)\n\nprintln(\"Integrator created for bilinear dynamics\")","category":"section"},{"location":"generated/tutorials/linear_system/#Step-4:-Define-the-Objective","page":"Linear System","title":"Step 4: Define the Objective","text":"Minimize control effort:\n\nobj = QuadraticRegularizer(:u, traj, 1.0)\n\nprintln(\"Objective: minimize ∫ ||u||² dt\")","category":"section"},{"location":"generated/tutorials/linear_system/#Step-5:-Create-and-Solve-the-Problem","page":"Linear System","title":"Step 5: Create and Solve the Problem","text":"Assemble the optimization problem:\n\nprob = DirectTrajOptProblem(traj, obj, integrator)\n\nprob\n\nprintln(\"Solving optimization problem...\")\nprintln(\"=\"^50)\n\nSolve with Ipopt:\n\nsolve!(prob; max_iter = 100, verbose = false)\n\nprintln(\"=\"^50)\nprintln(\"Optimization complete!\\n\")","category":"section"},{"location":"generated/tutorials/linear_system/#Step-6:-Analyze-the-Solution","page":"Linear System","title":"Step 6: Analyze the Solution","text":"Extract the solution:\n\nx_sol = prob.trajectory.x\nu_sol = prob.trajectory.u\ntimes = cumsum([0.0; prob.trajectory.Δt[:]])\n\nprintln(\"Solution analysis:\")\nprintln(\"  Initial state: \", x_sol[:, 1])\nprintln(\"  Final state: \", x_sol[:, end])\nprintln(\"  Goal state: \", x_goal)\nprintln(\"  Final error: \", norm(x_sol[:, end] - x_goal))\n\nControl statistics:\n\nu_norm = norm(u_sol)\nu_max = maximum(abs.(u_sol))\nu_mean = mean(abs.(u_sol))\n\nprintln(\"\\nControl statistics:\")\nprintln(\"  Total norm: \", u_norm)\nprintln(\"  Max magnitude: \", u_max)\nprintln(\"  Mean magnitude: \", u_mean)","category":"section"},{"location":"generated/tutorials/linear_system/#Step-7:-Verify-Dynamics","page":"Linear System","title":"Step 7: Verify Dynamics","text":"Check that the solution satisfies the dynamics at a few points:\n\nfunction verify_dynamics(x, u, Δt, G, k)\n    # Compute x[k+1] using the dynamics\n    x_k = x[:, k]\n    u_k = u[:, k]\n    Δt_k = Δt[k]\n    # Matrix exponential integration\n    x_k1_predicted = exp(Δt_k * G(u_k)) * x_k\n    x_k1_actual = x[:, k+1]\n\n    error = norm(x_k1_predicted - x_k1_actual)\n    return error\nend\n\nprintln(\"\\nDynamics verification (error at selected time steps):\")\nfor k in [1, 10, 25, 40, N-1]\n    error = verify_dynamics(x_sol, u_sol, prob.trajectory.Δt, G, k)\n    println(\"  k=$k: error = \", error)\nend","category":"section"},{"location":"generated/tutorials/linear_system/#Visualization-(Conceptual)","page":"Linear System","title":"Visualization (Conceptual)","text":"In a Jupyter notebook or with plotting packages, you could visualize:\n\nprintln(\"\\n\" * \"=\"^50)\nprintln(\"SOLUTION SUMMARY\")\nprintln(\"=\"^50)\n\nprintln(\"\\nState trajectory (first 10 and last 10 time steps):\")\nprintln(\"Time | x₁      | x₂\")\nprintln(\"-\"^25)\nfor k in [1:10; (N-9):N]\n    t = times[k]\n    println(@sprintf(\"%.2f | %7.4f | %7.4f\", t, x_sol[1, k], x_sol[2, k]))\nend\n\nprintln(\"\\nControl trajectory (first 10 and last 10 time steps):\")\nprintln(\"Time | u\")\nprintln(\"-\"^15)\nfor k in [1:10; (N-9):N]\n    t = times[k]\n    println(@sprintf(\"%.2f | %7.4f\", t, u_sol[1, k]))\nend","category":"section"},{"location":"generated/tutorials/linear_system/#Key-Takeaways","page":"Linear System","title":"Key Takeaways","text":"Linear interpolation provides a good initial guess for smooth problems\nBilinearIntegrator handles control-linear dynamics exactly\nBoundary conditions (initial/final) are enforced as hard constraints\nControl effort minimization produces smooth, efficient controls\nThe solver finds a solution that satisfies dynamics and reaches the goal","category":"section"},{"location":"generated/tutorials/linear_system/#Exercises","page":"Linear System","title":"Exercises","text":"Try modifying the problem:","category":"section"},{"location":"generated/tutorials/linear_system/#Exercise-1:-Change-the-goal","page":"Linear System","title":"Exercise 1: Change the goal","text":"Try reaching x_goal = [0.5, 0.5] instead","category":"section"},{"location":"generated/tutorials/linear_system/#Exercise-2:-Add-control-bounds","page":"Linear System","title":"Exercise 2: Add control bounds","text":"Limit the control: -1.0 ≤ u ≤ 1.0\n\ntraj_bounded = NamedTrajectory(\n    (x = x_guess, u = u_guess, Δt = fill(Δt, N));\n    timestep=:Δt,\n    controls=:u,\n    initial=(x = x_init,),\n    final=(x = x_goal,),\n    bounds=(u = 1.0,)\n)","category":"section"},{"location":"generated/tutorials/linear_system/#Exercise-3:-Vary-the-control-weight","page":"Linear System","title":"Exercise 3: Vary the control weight","text":"Try QuadraticRegularizer(:u, traj, 0.1) (less penalty) or QuadraticRegularizer(:u, traj, 10.0) (more penalty)","category":"section"},{"location":"generated/tutorials/linear_system/#Exercise-4:-Add-a-terminal-cost","page":"Linear System","title":"Exercise 4: Add a terminal cost","text":"Use soft goal constraint instead:\n\ntraj_soft = NamedTrajectory(\n    (x = x_guess, u = u_guess, Δt = fill(Δt, N));\n    timestep=:Δt,\n    controls=:u,\n    initial=(x = x_init,)  # No final constraint\n)\nobj_soft = QuadraticRegularizer(:u, traj_soft, 1.0) +\n           TerminalObjective(x -> 100.0 * norm(x - x_goal)^2, :x, traj_soft)","category":"section"},{"location":"generated/tutorials/linear_system/#Next-Steps","page":"Linear System","title":"Next Steps","text":"Bilinear Control Tutorial: Multiple drives and bounds\nMinimum Time Tutorial: Optimize trajectory duration\nSmooth Controls Tutorial: Add derivative penalties\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"generated/quickstart/#Quickstart-Guide","page":"Quickstart","title":"Quickstart Guide","text":"Welcome to DirectTrajOpt.jl! This guide will get you up and running in minutes.","category":"section"},{"location":"generated/quickstart/#What-is-DirectTrajOpt?","page":"Quickstart","title":"What is DirectTrajOpt?","text":"DirectTrajOpt.jl solves trajectory optimization problems - finding optimal control sequences that drive a dynamical system from an initial state to a goal state while minimizing a cost function.","category":"section"},{"location":"generated/quickstart/#Installation","page":"Quickstart","title":"Installation","text":"First, install the package:\n\nusing Pkg\nPkg.add(\"DirectTrajOpt\")\n\nYou'll also need NamedTrajectories.jl for defining trajectories:\n\nusing DirectTrajOpt\nusing NamedTrajectories\nusing LinearAlgebra\nusing CairoMakie","category":"section"},{"location":"generated/quickstart/#A-Minimal-Example","page":"Quickstart","title":"A Minimal Example","text":"Let's solve a simple problem: drive a 2D system from [0, 0] to [1, 0] with minimal control effort.","category":"section"},{"location":"generated/quickstart/#Step-1:-Define-the-Trajectory","page":"Quickstart","title":"Step 1: Define the Trajectory","text":"A trajectory contains your states, controls, and time information:\n\nN = 50  # number of time steps\ntraj = NamedTrajectory(\n    (\n        x = randn(2, N),    # 2D state\n        u = randn(1, N),    # 1D control\n        Δt = fill(0.1, N),   # time step\n    );\n    timestep = :Δt,\n    controls = :u,\n    initial = (x = [0.0, 0.0],),\n    final = (x = [1.0, 0.0],),\n    bounds = (Δt = (0.05, 0.2), u = 1.0),\n)","category":"section"},{"location":"generated/quickstart/#Step-2:-Define-the-Dynamics","page":"Quickstart","title":"Step 2: Define the Dynamics","text":"Specify how your system evolves. For bilinear dynamics ẋ = (G₀ + u₁G₁) x:\n\nG_drift = [-0.1 1.0; -1.0 -0.1]   # drift term\nG_drives = [[0.0 1.0; 1.0 0.0]]   # control term\nG = u -> G_drift + sum(u .* G_drives)\n\nintegrator = BilinearIntegrator(G, :x, :u, traj)","category":"section"},{"location":"generated/quickstart/#Step-3:-Define-the-Objective","page":"Quickstart","title":"Step 3: Define the Objective","text":"What do we want to minimize? Let's penalize control effort:\n\nobj = QuadraticRegularizer(:u, traj, 1.0)","category":"section"},{"location":"generated/quickstart/#Step-4:-Create-and-Solve","page":"Quickstart","title":"Step 4: Create and Solve","text":"Combine everything into a problem and solve:\n\nprob = DirectTrajOptProblem(traj, obj, integrator)\n\nThe problem summary shows the trajectory, objective, dynamics, and constraints:\n\nprob\n\nsolve!(prob; max_iter = 100, verbose = false)","category":"section"},{"location":"generated/quickstart/#Step-5:-Access-the-Solution","page":"Quickstart","title":"Step 5: Access the Solution","text":"Let's look at the results.\n\nplot(prob.trajectory)\n\nThe optimized trajectory is stored in prob.trajectory:\n\nprintln(\"Final state: \", prob.trajectory.x[:, end])\nprintln(\"Control norm: \", norm(prob.trajectory.u))","category":"section"},{"location":"generated/quickstart/#What-You-Can-Do","page":"Quickstart","title":"What You Can Do","text":"Multiple objectives: Combine regularization, minimum time, terminal costs\nFlexible dynamics: Linear, bilinear, time-dependent systems\nAdd constraints: Bounds, path constraints, custom nonlinear constraints\nSmooth controls: Penalize derivatives for smooth, implementable controls\nFree time: Optimize trajectory duration\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"#DirectTrajOpt.jl","page":"Home","title":"DirectTrajOpt.jl","text":"<div align=\"center\">\n  <table>\n    <tr>\n      <td align=\"center\">\n        <b>Documentation</b>\n        <br>\n        <a href=\"https://docs.harmoniqs.co/DirectTrajOpt/stable/\">\n          <img src=\"https://img.shields.io/badge/docs-stable-blue.svg\" alt=\"Stable\"/>\n        </a>\n        <a href=\"https://docs.harmoniqs.co/DirectTrajOpt/dev/\">\n          <img src=\"https://img.shields.io/badge/docs-dev-blue.svg\" alt=\"Dev\"/>\n        </a>\n      </td>\n      <td align=\"center\">\n        <b>Build Status</b>\n        <br>\n        <a href=\"https://github.com/harmoniqs/DirectTrajOpt.jl/actions/workflows/CI.yml?query=branch%3Amain\">\n          <img src=\"https://github.com/harmoniqs/DirectTrajOpt.jl/actions/workflows/CI.yml/badge.svg?branch=main\" alt=\"Build Status\"/>\n        </a>\n        <a href=\"https://codecov.io/gh/harmoniqs/DirectTrajOpt.jl\">\n          <img src=\"https://codecov.io/gh/harmoniqs/DirectTrajOpt.jl/branch/main/graph/badge.svg\" alt=\"Coverage\"/>\n        </a>\n      </td>\n      <td align=\"center\">\n        <b>License</b>\n        <br>\n        <a href=\"https://opensource.org/licenses/MIT\">\n          <img src=\"https://img.shields.io/badge/License-MIT-yellow.svg\" alt=\"MIT License\"/>\n        </a>\n      </td>\n    </tr>\n  </table>\n</div>\n\nDirectTrajOpt.jl is a framework for direct trajectory optimization via nonlinear programming. It converts continuous optimal control problems into finite-dimensional NLPs using direct transcription, then solves them with Ipopt.","category":"section"},{"location":"#Problem-Formulation","page":"Home","title":"Problem Formulation","text":"DirectTrajOpt solves problems of the form:\n\nbeginalign*\nundersetx_1N u_1Ntextminimize quad  J(x_1N u_1N) \ntextsubject to quad  f(x_k+1 x_k u_k Delta t t_k) = 0 quad k = 1 ldots N-1\n c_k(x_k u_k) geq 0 quad k = 1 ldots N \n x_1 = x_textinit quad x_N = x_textgoal \nendalign*\n\nwhere:\n\nJ(x, u) is the objective function to minimize\nf(.) represents system dynamics encoded via integrators\nc(.) represents additional nonlinear constraints\nx is the state trajectory\nu is the control trajectory","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"using Pkg\nPkg.add(\"DirectTrajOpt\")","category":"section"},{"location":"#Quick-Example","page":"Home","title":"Quick Example","text":"using DirectTrajOpt\nusing NamedTrajectories\n\n# Define trajectory\ntraj = NamedTrajectory(\n    (x = randn(2, 50), u = randn(1, 50), Δt = fill(0.1, 50));\n    timestep=:Δt,\n    controls=:u,\n    initial=(x = [0.0, 0.0],),\n    final=(x = [1.0, 0.0],)\n)\n\n# Define dynamics: dx/dt = (A + u * B) * x\nG_drift = [-0.1 1.0; -1.0 -0.1]\nG_drives = [[0.0 1.0; 1.0 0.0]]\nG = u -> G_drift + sum(u .* G_drives)\nintegrator = BilinearIntegrator(G, :x, :u, traj)\n\n# Define objective\nobj = QuadraticRegularizer(:u, traj, 1.0)\n\n# Create and solve problem\nprob = DirectTrajOptProblem(traj, obj, integrator)\nsolve!(prob; max_iter=100)","category":"section"},{"location":"#Key-Features","page":"Home","title":"Key Features","text":"Flexible dynamics: Define system evolution via bilinear, time-dependent, or derivative integrators\nModular objectives: Combine cost terms with + and * (regularization, minimum time, terminal cost, etc.)\nConstraint support: Bounds, equality, nonlinear, symmetry, and L1 slack constraints\nAutomatic differentiation: Sparse Jacobians and Hessians via ForwardDiff\nSolver callbacks: Monitor and control the optimization process","category":"section"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"#Building-Documentation","page":"Home","title":"Building Documentation","text":"This package uses a shared Documenter config. First-time setup:\n\n./docs/get_docs_utils.sh\n\nBuild docs:\n\njulia --project=docs docs/make.jl\n\nLive editing:\n\njulia --project=docs -e '\n  using LiveServer, DirectTrajOpt, Revise\n  servedocs(\n    literate_dir=\"docs/literate\",\n    skip_dirs=[\"docs/src/generated\", \"docs/src/assets/\"],\n    skip_files=[\"docs/src/index.md\"]\n  )'\n\nNote: servedocs will loop if it watches generated files. Ensure all generated files are in the skip dirs/files args.","category":"section"}]
}
